[
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Count models"
  },
  {
    "objectID": "regression_count_data.html#not-sure-where-to-put",
    "href": "regression_count_data.html#not-sure-where-to-put",
    "title": "2  Modelling counts",
    "section": "2.1 Not sure where to put…",
    "text": "2.1 Not sure where to put…\nA GLM model contains 3 main components\n\nThe response distribution - we need to assume a distribution for the response variable \\(y_i\\), e.g. \\(y_i \\sim \\mathrm{poisson}(\\lambda_i)\\).\nThe predictor function - a deterministic function of the covariates and model coefficients.\nA link - between the expected value of the distribution and the predictor function.\n\nNever start with overdispersion or zero-inflation models. First start simple (this is always the Poisson model for count data), fit and validate the simple model and then find solutions to problems. People often think that just because we have many zeros in our data we need to use, or should use, a zero-inflated model. This is not the case - we may have covariates which can explain the excess number of zeros.\nThe Poisson distribution is a maximum-entropy distribution (least informative).\nThe log-link \\(\\mu_i = \\exp(\\eta_i) = \\exp(\\pmb x_i\\pmb\\beta)\\) ensures the the expected values are always positive. This is a nice restriction for count data.\nThroughout this material we talk a lot about hetergeneity parameters, aka overdispersion parameters, aka dispersion parameters. This is not to be confused with the dispersion statistic\ndisp_stat_i = (observed data i - modelled expected value i)/sqrt(modelled var i) = residual i / sqrt(var i)\nsee SMS:ZIGLMAGLMM video @ 24:45."
  },
  {
    "objectID": "regression_count_data.html#poisson",
    "href": "regression_count_data.html#poisson",
    "title": "2  Modelling counts",
    "section": "2.2 Poisson",
    "text": "2.2 Poisson\nFor a regression model \\(Y = \\pmb\\beta\\pmb X + \\epsilon_i\\), the canonical likelihood function when \\(Y\\) is a count variable is the Poisson (\\(Y \\sim Poisson(\\lambda)\\)), with probability mass function\n\\[\nP(Y = y_i |\\pmb x_i) =\n  \\frac{\\exp(-\\lambda_i)\\lambda_i^{y_i}}\n       {\\Gamma(1 + y_i)}\n\\]\nfor \\(E(y_i|\\pmb x_i) = \\lambda_i = \\mu_i = \\exp(\\pmb \\beta \\pmb x_i)\\) and \\(Var(y_i | \\pmb x_i) = \\lambda_i\\). The signature features of the Poisson model are its loglinear conditional mean function \\(\\log E(y_i|\\pmb x_i) = \\log \\mu_i = \\pmb \\beta \\pmb x_i\\) (the log of the conditional mean is linear in the parameters), and equal mean and variance \\(Var(y_i | \\pmb x_i) = \\lambda_i\\) which is also called equidispersion since the dispersion \\(\\frac{\\text{variance}}{\\text{mean}} = 1\\).\nHowever, Poisson models tend to be a poor fit in many ecological contexts due to overdispersion. Overdispersion arises naturally due to heterogeneity (e.g. as fish cluster in preferred habitats; as transient schooling species lead to some very large abundance observations), dependence between observations due to spatial and temporal autocorrelation (e.g. dependence of fish abundance within sites and years), and zero-inflation. It may also be due to artifacts of sampling and not measuring or controlling for key covariates influencing local patterns of fish abundance (e.g. time of day, tides, etc). The most popular distribution for overdispersed counts in ecological studies is the negative binomial (NB), which has been shown to appropriately model overdispersion in a range of ecological contexts (Stoklosa et al, 2022)."
  },
  {
    "objectID": "regression_count_data.html#extra-poisson-dispersion",
    "href": "regression_count_data.html#extra-poisson-dispersion",
    "title": "2  Modelling counts",
    "section": "2.3 Extra-poisson dispersion",
    "text": "2.3 Extra-poisson dispersion\nFor the poisson we have \\(E[y_i | \\pmb x_i] = \\mathrm{Var}[y_i | \\pmb x_i]\\). Models which account for ‘extra-poisson dispersion’ do so through the use of an extra parameter such that \\(E[y_i | \\pmb x_i] = \\phi\\mathrm{Var}[y_i | \\pmb x_i]\\), for extra-poisson dispersion parameter \\(\\phi\\)."
  },
  {
    "objectID": "regression_count_data.html#sec-NB2",
    "href": "regression_count_data.html#sec-NB2",
    "title": "2  Modelling counts",
    "section": "2.4 Negative Binomial (NB-2)",
    "text": "2.4 Negative Binomial (NB-2)\nThe derivation on the negative binomial NB2 is usually illustrated as a Poisson model with gamma heterogeneity, where the gamma noise has a mean of 1.1 An intuitive way to think of this is through the introduction of latent heterogeneity2 (an unobserved effect) to the mean of the Poisson model (Greene, 2008).\nRecall our Poisson model of \\(y_i \\sim \\mathrm{poisson}(\\lambda_i)\\) for \\(\\lambda_i = \\mu_i = \\exp(\\pmb x_i \\pmb\\beta)\\)3 which has the property of equidispersion since \\(E[y_i | \\pmb x_i] = \\mathrm{Var}[y_i | \\pmb x_i] = \\lambda_i\\). We will alter this poisson model to account for extra variance in our data, i.e. overdispersion \\(\\mathrm{Var}[y_i | \\pmb x_i] > E[y_i | \\pmb x_i]\\). We can imagine this extra variance stemming from observation-level deviations from the mean dues to an unobserved effect; we will refer to these deviations as latent heterogeneity. Let \\(\\varepsilon\\) represent this latent heterogeneity, then we can re-express the mean as \\(\\mu_i^* = \\exp(\\pmb x_i \\pmb\\beta + \\varepsilon_i)\\). Here \\(\\varepsilon\\) is its own random variable to which we will assign a probability distribution. Now define \\(h_i = \\exp(\\varepsilon_i)\\) such that\n\\[\ny_i \\sim \\mathrm{poisson}(h_i\\lambda_i)\n\\]\nThis is a common step in the derivation of models for overdispersed counts, where the assumed distribution of \\(h_i\\) leads to different models and parameterizations. For the negative binomial (NB2) model we assume that \\(h_i\\) follows a single-parameter gamma distribution\n\\[\nh_i \\sim \\mathrm{gamma}(k = \\theta, \\; \\theta)\n\\]\nwith mean 1 and variance \\(\\alpha = 1/\\theta\\). The probability density of \\(h_i\\) is then\n\\[\nf(h_i) =\n  \\frac{\\theta^\\theta \\exp(-\\theta h_i)h_i^{\\theta - 1}}\n       {\\Gamma(\\theta)}\n  \\; ;\\;\\; h_i \\geq 0 ,\\; \\theta > 0 \\;.\n\\]\nTo put this in mathematical terms, the negative binomial distribution is a poisson-gamma mixture. Notice that a mean of 1 for \\(h\\) corresponds to a mean of 0 for \\(\\varepsilon\\), i.e. we account for some extra zero-centered deviation around \\(\\pmb x_i \\pmb\\beta\\). To put this another way, for \\(y_i \\sim \\mathrm{poisson}(h_i\\lambda_i)\\), if \\(E[h_i] = 1\\) then we can see that \\(E[y_i] = \\lambda_i\\). I.e. \\(E[h_i] = 1\\) is the multiplicative equivalent of \\(E[\\varepsilon] = 0\\) in the additive case. This kind of mixing based on multiplicative heterogeneity which on average leaves the Poisson mean unchanged allows us to increase the variability in the Poisson mean, and in turn, the variability of the response. Intuitively this will lead to overdispersion and to increased probabilities of the occurrence of low counts and of high counts.\nNow we have our latent heterogeneity within the conditional mean of the Poisson model4 we can write the the conditional distribution \\(f(y_i|x_i, h_i) = \\prod^n_{i=1}g(y_i | h_i\\lambda_i)\\) where \\(g\\) is the probability density function of the \\(\\mathrm{poisson}(h_i \\lambda_i)\\) (Gourieroux, 1984). However, since \\(\\varepsilon\\) is an unobserved variable, and therefore so is \\(h\\), we must integrate \\(h\\) out to obtain the conditional distribution of interest\n\\[\nf(y_i|x_i) = P[Y=y_i | \\pmb x_i] = \\int\n  \\frac{\\exp(-h_i\\lambda_i)(h_i\\lambda_i)^{y_i}}\n       {y_i!}\\times\n  \\frac{\\theta^\\theta \\exp(-\\theta h_i)h_i^{\\theta - 1}}\n       {\\Gamma(\\theta)}dh_i\n\\]\nWe will spare the maths5 and take for granted that we get\n\\[\n\\boxed{\n\\begin{align}\n\\textbf{Negative binomial (NB-2)}&: \\quad y_i \\sim \\mathcal{NB}_2\\left(\\lambda_i \\equiv \\mu_i,\\; \\theta \\equiv \\alpha^{-1}\\right) \\\\ \\\\\n\\text{ A poisson-gamma mixture }& \\text{with} \\; y_i \\sim \\mathrm{poisson}(h_i \\lambda_i) \\text{ and } h_i \\sim \\mathrm{gamma}(\\theta, \\theta) .\n\\\\ \\\\ \\\\\nP[Y=y_i | \\pmb x_i]\n  &= \\frac{\\Gamma(y_i + \\theta)}\n          {\\Gamma(y_i + 1)\\Gamma(\\theta)}\n     \\left(\\frac{\\theta}\n              {\\theta + \\mu_i}\n     \\right)^\\theta\n     \\left(1- \\frac{\\theta}\n                  {\\theta + \\mu_i}\n     \\right)^{y_i}\\\\ \\\\\n  &= \\frac{\\Gamma(y_i + 1/\\alpha)}\n          {\\Gamma(y_i + 1)\\Gamma(1/\\alpha)}\n     \\left(\\frac{1}\n                {\\alpha\\mu_i + 1}\n     \\right)^{1/\\alpha}\n     \\left(1- \\frac{1}\n                   {\\alpha \\mu_i + 1}\n     \\right)^{y_i} \\\\ \\\\ \\\\\nE[y_i|\\pmb x_i] &= \\lambda_i = \\mu_i = \\exp(\\pmb x_i\\pmb\\beta)\\\\ \\\\ \\\\\n\\mathrm{Var}[y_i|\\pmb x_i]\n  &= \\mu_i\\left(\\frac{\\mu_i}{\\theta} + 1 \\right)\\\\\n  &= \\mu_i\\big(\\alpha \\mu_i + 1\\big)\\\\ \\\\ \\\\\n\\text{for } \\; y_i \\in \\mathbb{Z}^{0+}, \\; \\theta > 0, \\; \\text{and }&\\text{heterogeneity/overdispersion parameter } \\alpha = 1/\\theta > 0.\\quad\n\\end{align}\n}\n\\tag{2.1}\\]\nThis is the NB-2 parameterization of the negative binomial model (named by CT, 1986 in reference to the quadratic exponent of \\(\\mu\\) in the conditional variance function) — the standard parameterization for NB regression. Notice that this parameterization, resulting from the inclusion of a latent heterogeneity effect, relaxes the equidispersion restriction of the Poisson model while preserving the same conditional mean.\nThe Poisson model is nested within the NB2 model as the boundary case when \\(\\alpha = 0\\). So is the geometric model when \\(\\alpha = 1\\).\nThe variance to mean ratio describes the ‘extra-Poisson dispersion’ (overdispersion). Here we have \\[\n\\frac{\\text{Variance}}{\\text{Mean}} = \\frac{\\mu_i(\\alpha\\mu_i + 1)}{\\mu_i} = \\alpha\\mu_i + 1\n\\]\nNotice that the overdispersion depends on \\(i\\), i.e. it is variable. This is why the NB2 parameterization is sometimes called the variable overdisperison NB.\n\n\n\n\n\n\nDifferent names for the same thing\n\n\n\nThe negative binomial PMF is found in many different forms. \\(\\lambda\\) or \\(\\mu\\), \\(\\alpha\\) or \\(1/\\theta\\), \\(\\alpha\\) could be called \\(\\phi\\) and \\(\\theta\\) could be \\(\\nu\\). Some authors prefer to leave the gamma scale parameter, \\(\\theta\\), as it is. In this form the heterogeneity parameter (\\(\\theta\\)) is inversely related to the amount of Poisson overdispersion in the data. Most contemporary statisticians, however, prefer a direct relationship. Hence the use of \\(\\alpha = 1/\\theta\\).\n\n\n\n\n\n\n\n\nSummary\n\n\n\nHere we saw the Negative Binomial (NB-2 paramaterization) is a Poisson model with latent heterogeneity distributed as single-parameter gamma. This gamma noise overcomes the equidispersion limitation of the Poisson model, accomodating overdispersed or correlated counts through the addition of an overdispersion parameter in the NB variance, but still retain the same conditional mean. The distribution is parameterized by its mean \\(\\mu_i = \\lambda_i\\) and heterogeneity parameter \\(\\alpha\\) (aka. overdispersion parameter) which is the inverse of the gamma noise parameter \\(\\theta\\). This parameterization is intuitive in the context of regression for overdispersed counts, however many other parameterizations exist.\n\n\n\n\n\n\n\n\nPonder\n\n\n\nHere we distributed our latent heterogeneity term as gamma. What is special about the gamma distribution? What would happen if we used a different distribution? The answers could be in Hilbe (2011)."
  },
  {
    "objectID": "regression_count_data.html#sec-NB1",
    "href": "regression_count_data.html#sec-NB1",
    "title": "2  Modelling counts",
    "section": "2.5 Negative Binomial (NB-1)",
    "text": "2.5 Negative Binomial (NB-1)\nThe NB1 (aka linear NB, constant dispersion NB) is derived as a Poisson-gamma mixture model, however the manner of derivation differs from the traditional NB2 model. First derived by Evans (1953), it begins with the Poisson distribution\n\\[\ny_i \\sim \\mathrm{Poisson}(\\lambda_i); \\quad\n  P[Y = y_i | \\lambda_i] =\n  \\frac{e^{-\\lambda_i}\\lambda_i^{y_i}}\n       {y_i!}\n\\]\nFor the NB1, we assume the Poisson parameter itself is distributed gamma as\n\\[\n\\lambda_i \\sim \\mathrm{gamma}(\\mu_i, \\delta)\n\\]\nwhere we assign the mean \\(\\mu_i = \\exp(\\pmb x_i \\pmb\\beta)\\) to the shape parameter, and \\(\\delta\\) is the scale parameter.6 7\n\n\n\n\n\n\nThe above is shown as \\(Gamma(\\delta, \\mu_i)\\) in multiple of Hilbe’s textbooks, where delta is still the scale parameter and mu the shape. Is it Gamma(shape, scale) or Gamma(scale, shape)?\n\n\n\nAs such, the expected value of the Poisson parameter is \\(E[\\lambda_i] = \\mu_i/\\delta\\) and the variance is \\(\\mathrm{Var}[\\lambda_i] = \\mu_i/\\delta^2\\). The resulting Poisson-gamma mixture, integrating out \\(\\lambda\\) can be defined as\n\\[\nf(y_i|\\pmb x_i) = \\int^\\infty_0\n  \\frac{e^{-\\lambda_i}\\lambda_i^{y_i}}\n       {y_i!}\n  \\frac{\\delta^{\\mu_i}\\lambda_i^{\\mu_i - 1}}\n       {\\Gamma(\\mu_i)}\n  \\exp(-\\lambda_i\\delta) \\; d\\lambda\n\\]\nSparing the math8 we get\n\\[\n\\boxed{\n\\begin{align}\n\\textbf{Negative binomial (NB-1)}&: \\quad y_i \\sim \\mathcal{NB}_1\\left(\\mu_i,\\; \\delta \\equiv \\alpha^{-1}\\right) \\\\ \\\\\nP[Y=y_i | \\pmb x_i]\n  &= \\frac{\\Gamma(y_i + \\mu_i)}\n          {\\Gamma(y_i + 1)\\Gamma(\\mu_i)}\n     \\left(\\frac{\\delta}\n                {\\delta + 1}\n     \\right)^{\\mu_i}\n     \\left(\\frac{1}\n                   {\\delta + 1}\n     \\right)^{y_i} \\\\ \\\\\n  &= \\frac{\\Gamma(y_i + \\mu_i)}\n          {\\Gamma(y_i + 1)\\Gamma(\\mu_i)}\n     \\left(\\frac{1}\n                {\\alpha + 1}\n     \\right)^{\\mu_i}\n     \\left(\\frac{\\alpha}\n                {\\alpha + 1}\n     \\right)^{y_i} \\\\ \\\\ \\\\\nE[y_i|\\pmb x_i]\n  &= \\frac{\\exp(\\pmb x_i\\pmb\\beta)}\n          {\\delta}\n  = \\frac{\\mu_i}\n          {\\delta}  \n  =  \\alpha \\mu_i\\\\ \\\\\n\\mathrm{Var}[y_i|\\pmb x_i]\n  &= \\frac{\\mu_i (\\delta + 1)}\n          {\\delta^2}\n  =  \\alpha\\mu_i(\\alpha + 1)\\\\ \\\\\n\\text{for } \\; y_i \\in \\mathbb{Z}^{0+}, \\; \\delta > 0, \\; \\text{and }&\\text{ heterogeneity/overdispersion parameter } \\alpha = 1/\\theta > 0.\\quad\n\\end{align}\n}\n\\tag{2.2}\\]\nAgain we have the nested Poisson model as the boundary case when \\(\\alpha = 0\\).\nThe variance to mean ratio, denoting the ‘extra-Poisson dispersion’ (i.e. overdispersion), is\n\\[\n\\frac{\\text{Variance}}{\\text{Mean}} = \\frac{\\mu_i(\\delta + 1)/\\delta^2}{\\mu_i/\\delta} = \\frac{\\delta + 1}{\\delta} = \\alpha + 1\n\\]\nNotice that unlike the NB2 parameterization, in which the overdispersion was variable, here the overdispersion is constant. This is why the NB1 is sometimes called the constant overdispersion NB.\n\n\n\n\n\n\nWhat’s in a parameterization: NB2 vs. NB1 (CT, 1986)\n\n\n\nThe parameterization of the NB model is determined by the parameterization of the gamma heterogeneity distribution. As such, the NB2 and NB1 parameterizations imply different assumptions about the functional form of heteroscedasticity — a point which is not emphasized in the literature — and hence in general will lead to different estimates of \\(\\pmb\\beta\\). The two alternative specifications of the gamma heterogeneity distribution amount to different parameterizations in the univariate model, but where a regression component is present they lead to different models. This difference is also relevant when we consider the test of the null hypothesis that the distribution of Y is Poisson against the alternative that it is negative binomial.\nNote that for the intercept only model \\(\\mu_i = \\beta\\) (i.e. no \\(x\\) variables in the model), if observations are i.i.d., the specific NB parameterization and resulting difference in model form is of no consequence."
  },
  {
    "objectID": "regression_count_data.html#sec-GenPois",
    "href": "regression_count_data.html#sec-GenPois",
    "title": "2  Modelling counts",
    "section": "2.6 Generalized Poisson",
    "text": "2.6 Generalized Poisson\nWhen there is overdispersion due to latent heterogeneity, people often assume a gamma mixture of poisson variables. Suppose that is \\(\\varepsilon_i\\) is an unobserved individual heterogeneity factor (e.g. an unobserved covariate), with \\(\\exp(\\varepsilon)\\) following a gamma distribution with mean 1 (i.e. single parameter gamma distribution) and variance \\(\\alpha\\). Now assume the response vector follows a modification of the Poisson model with mean \\(\\lambda^*_i = \\exp(\\pmb x_i \\pmb\\beta + \\varepsilon_i)\\). The result is the well-known negative binomial regression model where \\(\\alpha\\) is a nonnegative parameter, indicating the degree of overdispersion.\nAs alternative to the negative binomial for overdispersed counts we may assume the response follows a generalized poisson (GP) distribution. Originally developed by Consul and Jain (1973), it has since undergone various modifications (the restricted generalized Poisson, three parameterizations of a hybrid generalized Poisson, etc).\nThe generalized poisson model is similar to the negative binomial in that it incorporates an extra heterogeneity parameter.9 However, whereas the negative binomial hetergeneity parameter (\\(\\alpha\\)) is based on the single-parameter gamma distribution (NB2 parameterization; Section 2.4), the heterogeneity parameter employed by the generalized poisson is based on the lognormal distribution.10 This allows modelling of both overdispersed ?and underdispersed data?.\nThere are several different models that are referred to as generalized poisson models.\n\nThe standard parameterization comes from Consul (1989) (detailed in Consul and Famoye, 1992; shown to be a poisson mixture in Joe and Zhu, 2005). In Consul and Famoye (1992) the model is specified to deal with underdispersion to some degree, however it seems like this parameterization has been restricted to overdispersion only (\\(\\delta > 0\\)) in later works (see Joe and Zhu, 2005).\n\n\\[\n\\boxed{\n  \\begin{align}\n    \\textbf{Generalized poisson} & \\text{ (Consul, 1989)}: \\quad\n    y_i \\sim \\mathrm{GenPois}(\\theta_i, \\delta)\n    \\\\\\\\\n    P[Y = y_i | \\pmb x_i, \\pmb\\beta]\n      &= \\theta_i(\\theta_i + \\delta y_i)^{y_i - 1}\n         \\frac{\\exp(-\\theta_i-\\delta y_i)}\n              {y!} \\\\ \\\\\n    E[Y_i|\\theta_i, \\delta]\n      &= \\mu_i = \\frac{\\theta_i}\n                      {1-\\delta} \\\\ \\\\\n    \\mathrm{Var}(Y_i | \\theta_i, \\delta)\n      &= \\frac{\\theta_i}\n              {(1-\\delta)^3} \\\\ \\\\\n      &= \\frac{1}\n              {(1-\\delta)^2} E[y_i] \\\\ \\\\\n      &= \\phi E[y_i]\\\\ \\\\\n  \\text{ for } \\; y_i \\in \\mathbb{Z}^{0+}, \\;\\; \\theta_i > 0, \\;\\; & \\max(-1, -\\theta_i/4) < \\delta < 1, \\; \\text{and}\\\\\n  \\text{overdispersion parame}&\\text{ter } \\phi = 1/(1-\\delta)^2.\\quad\n  \\end{align}\n}\n\\tag{2.3}\\]\nWhen \\(\\delta = 0 \\;\\Leftrightarrow\\; \\phi = 1\\) the GP reduces to the nested Poisson distribution with parameter \\(\\theta_i\\). When \\(\\delta < 0 \\;\\Leftrightarrow\\; \\phi < 1\\) we have underdispersion and for \\(\\delta > 0 \\;\\Leftrightarrow\\; \\phi > 1\\) we have overdispersion.\nConsol (1989) introduce covariates into a regression model based on the GP distirbution via\n\\[\nE[y_i] = \\frac{\\theta_i}{1-\\delta} = \\mu_i = \\exp(\\pmb x_i\\pmb\\beta)\n\\]\nUnder this parameterization the corresponding GP regression model is obtained by subbing \\(\\theta_i = (1-\\delta)\\mu_i\\) into Equation 2.3 to get \\[\nP(Y = y_i | \\pmb x_i, \\pmb \\beta, \\delta)\n  = \\frac{(1-\\delta)\\mu_i \\big[(1 - \\delta)\\mu_i + \\delta y_i \\big]^{y_i - 1} \\exp\\big(-(1-\\delta)\\mu_i - \\delta y_i \\big)}{y!}\n\\]\nfor \\(\\mu_i > 0\\), \\(\\max(-1, -\\theta_i/4) < \\delta \\leq 1\\) and \\(E[y_i] = \\mu_i = \\exp(\\pmb x_i\\pmb\\beta)\\) (Yang, 2007).\n\n\n\n\n\n\n\n\nWrong generalized poisson definition in Hilbe (2011)?\n\n\n\n\n\nThe below is from Hilbe (2011). Note that this is a different definition to that used in Consul and Famoye (1992), Joe and Zhu (2005), and Hardin and Hilbe (2018). Is this an error? Perhaps there is equality between the two and I just don’t see it. I will steer clear of the Hilbe (2011) definition.\n\n\n\n\nThe value \\(\\theta\\) serves as the heterogeneity parameter, analogous to the negative binomial heterogeneity parameter \\(\\alpha\\), and reflects the amount of ‘extra-poisson’ dispersion in the data. As with the NB \\(\\alpha\\), as \\(\\theta\\) approaches zero this parameterization reduces to the Poisson distribution.\n\nAnother well-known parameterization is given in Famoye and Singh (2006) and Winkelmann (2008).\n\\[\n\\boxed{\n  \\begin{align}\n    \\textbf{Generalized poisson} & \\text{ - Famoye and Singh (2006) parameterization} \\\\ \\\\\n    P[Y = y_i | \\mu_i, \\alpha]\n      &= \\left(\n            \\frac{\\mu_i}\n                 {\\alpha\\mu_i + 1}\n          \\right)^{y_i}\n          \\left(\n            \\frac{(\\alpha y_i + 1)^{y_i - 1}}\n                 {y!}\n          \\right)\n          \\exp\\left(\n            \\frac{-\\mu_i(\\alpha y_i + 1)}\n                 {\\alpha \\mu_i + 1}\n          \\right)\n    \\\\ \\\\\n    E[y_i|\\mu_i, \\alpha]\n      &= \\mu_i \\\\ \\\\\n    \\mathrm{Var}[y_i | \\mu_i, \\alpha]\n      &= \\mu_i(1 - \\alpha\\mu_i)^2 \\\\ \\\\\n  \\text{for heterogeneity }&\\text{parameter } \\alpha.\n  \\end{align}\n}\n\\]\nfor heterogeneity parameter \\(\\alpha\\). Again, as \\(\\alpha \\to 0\\), this generalized Poisson distribution is reduced to the Poisson."
  },
  {
    "objectID": "regression_count_data.html#summary-1",
    "href": "regression_count_data.html#summary-1",
    "title": "2  Modelling counts",
    "section": "2.7 Summary",
    "text": "2.7 Summary\n\ncol_names <- c(\n  \"Family\",\n  \"Parameterization\", \n  \"Heterogeneity parameter\",\n  \"Nested models\",\n  \"Extra-poisson dispersion\"\n)\ntab <- data.frame() |>  \n  rbind(c(\n    \"Negative Binomial\", \n    \"NB2\", \n    \"\\\\alpha\", \n    \"Poisson ($\\\\alpha = 0)\", \n    \"\"\n  )) \n  # Add more rows here\n\ncolnames(tab) <- col_names"
  },
  {
    "objectID": "regression_count_data.html#resourcesreferences",
    "href": "regression_count_data.html#resourcesreferences",
    "title": "2  Modelling counts",
    "section": "2.8 Resources/references",
    "text": "2.8 Resources/references\n\nEvans, 1953\nConsul and Jain, 1973\nBulmer, 1974\nJanardan et al, 1979\nGourieroux, 1984\nCT, 1986\nCT, 2013\nConsul and Famoye, 1992\nJoe and Zhu, 2005\nFamoye and Singh, 2006\nGreene, 2008\nWinkelmann, 2008\nHilbe, 2011\nHardon and Hilbe, 2018\nhttps://www.youtube.com/watch?v=uGKnoAw-PFQ\nStatistical Methods Series: Zero-Inflated GLM and GLMM"
  },
  {
    "objectID": "ch_modelling_counts/regression_count_data.html#not-sure-where-to-put",
    "href": "ch_modelling_counts/regression_count_data.html#not-sure-where-to-put",
    "title": "2  Modelling counts",
    "section": "2.1 Not sure where to put…",
    "text": "2.1 Not sure where to put…\nA GLM model contains 3 main components\n\nThe response distribution - we need to assume a distribution for the response variable \\(y_i\\), e.g. \\(y_i \\sim \\mathrm{poisson}(\\lambda_i)\\).\nThe predictor function - a deterministic function of the covariates and model coefficients.\nA link - between the expected value of the distribution and the predictor function.\n\nNever start with overdispersion or zero-inflation models. First start simple (this is always the Poisson model for count data), fit and validate the simple model and then find solutions to problems. People often think that just because we have many zeros in our data we need to use, or should use, a zero-inflated model. This is not the case - we may have covariates which can explain the excess number of zeros.\nThe Poisson distribution is a maximum-entropy distribution (least informative).\nThe log-link \\(\\mu_i = \\exp(\\eta_i) = \\exp(\\pmb x_i\\pmb\\beta)\\) ensures the the expected values are always positive. This is a nice restriction for count data.\nThroughout this material we talk a lot about hetergeneity parameters, aka overdispersion parameters, aka dispersion parameters. This is not to be confused with the dispersion statistic\ndisp_stat_i = (observed data i - modelled expected value i)/sqrt(modelled var i) = residual i / sqrt(var i)\nsee SMS:ZIGLMAGLMM video @ 24:45."
  },
  {
    "objectID": "ch_modelling_counts/regression_count_data.html#poisson",
    "href": "ch_modelling_counts/regression_count_data.html#poisson",
    "title": "2  Modelling counts",
    "section": "2.2 Poisson",
    "text": "2.2 Poisson\nFor a regression model \\(Y = \\pmb\\beta\\pmb X + \\epsilon_i\\), the canonical likelihood function when \\(Y\\) is a count variable is the Poisson (\\(Y \\sim Poisson(\\lambda)\\)), with probability mass function\n\\[\nP(Y = y_i |\\pmb x_i) =\n  \\frac{\\exp(-\\lambda_i)\\lambda_i^{y_i}}\n       {\\Gamma(1 + y_i)}\n\\]\nfor \\(E(y_i|\\pmb x_i) = \\lambda_i = \\mu_i = \\exp(\\pmb \\beta \\pmb x_i)\\) and \\(Var(y_i | \\pmb x_i) = \\lambda_i\\). The signature features of the Poisson model are its loglinear conditional mean function \\(\\log E(y_i|\\pmb x_i) = \\log \\mu_i = \\pmb \\beta \\pmb x_i\\) (the log of the conditional mean is linear in the parameters), and equal mean and variance \\(Var(y_i | \\pmb x_i) = \\lambda_i\\) which is also called equidispersion since the dispersion \\(\\frac{\\text{variance}}{\\text{mean}} = 1\\).\nHowever, Poisson models tend to be a poor fit in many ecological contexts due to overdispersion. Overdispersion arises naturally due to heterogeneity (e.g. as fish cluster in preferred habitats; as transient schooling species lead to some very large abundance observations), dependence between observations due to spatial and temporal autocorrelation (e.g. dependence of fish abundance within sites and years), and zero-inflation. It may also be due to artifacts of sampling and not measuring or controlling for key covariates influencing local patterns of fish abundance (e.g. time of day, tides, etc). The most popular distribution for overdispersed counts in ecological studies is the negative binomial (NB), which has been shown to appropriately model overdispersion in a range of ecological contexts (Stoklosa et al, 2022)."
  },
  {
    "objectID": "ch_modelling_counts/regression_count_data.html#extra-poisson-dispersion",
    "href": "ch_modelling_counts/regression_count_data.html#extra-poisson-dispersion",
    "title": "2  Modelling counts",
    "section": "2.3 Extra-poisson dispersion",
    "text": "2.3 Extra-poisson dispersion\nFor the poisson we have \\(E[y_i | \\pmb x_i] = \\mathrm{Var}[y_i | \\pmb x_i]\\). Models which account for ‘extra-poisson dispersion’ do so through the use of an extra parameter such that \\(E[y_i | \\pmb x_i] = \\phi\\mathrm{Var}[y_i | \\pmb x_i]\\), for extra-poisson dispersion parameter \\(\\phi\\)."
  },
  {
    "objectID": "ch_modelling_counts/regression_count_data.html#sec-NB2",
    "href": "ch_modelling_counts/regression_count_data.html#sec-NB2",
    "title": "2  Modelling counts",
    "section": "2.4 Negative Binomial (NB-2)",
    "text": "2.4 Negative Binomial (NB-2)\nThe derivation on the negative binomial NB2 is usually illustrated as a Poisson model with gamma heterogeneity, where the gamma noise has a mean of 1.1 An intuitive way to think of this is through the introduction of latent heterogeneity2 (an unobserved effect) to the mean of the Poisson model (Greene, 2008).\nRecall our Poisson model of \\(y_i \\sim \\mathrm{poisson}(\\lambda_i)\\) for \\(\\lambda_i = \\mu_i = \\exp(\\pmb x_i \\pmb\\beta)\\)3 which has the property of equidispersion since \\(E[y_i | \\pmb x_i] = \\mathrm{Var}[y_i | \\pmb x_i] = \\lambda_i\\). We will alter this poisson model to account for extra variance in our data, i.e. overdispersion \\(\\mathrm{Var}[y_i | \\pmb x_i] > E[y_i | \\pmb x_i]\\). We can imagine this extra variance stemming from observation-level deviations from the mean dues to an unobserved effect; we will refer to these deviations as latent heterogeneity. Let \\(\\varepsilon\\) represent this latent heterogeneity, then we can re-express the mean as \\(\\mu_i^* = \\exp(\\pmb x_i \\pmb\\beta + \\varepsilon_i)\\). Here \\(\\varepsilon\\) is its own random variable to which we will assign a probability distribution. Now define \\(h_i = \\exp(\\varepsilon_i)\\) such that\n\\[\ny_i \\sim \\mathrm{poisson}(h_i\\lambda_i)\n\\]\nThis is a common step in the derivation of models for overdispersed counts, where the assumed distribution of \\(h_i\\) leads to different models and parameterizations. For the negative binomial (NB2) model we assume that \\(h_i\\) follows a single-parameter gamma distribution\n\\[\nh_i \\sim \\mathrm{gamma}(k = \\theta, \\; \\theta)\n\\]\nwith mean 1 and variance \\(\\alpha = 1/\\theta\\). The probability density of \\(h_i\\) is then\n\\[\nf(h_i) =\n  \\frac{\\theta^\\theta \\exp(-\\theta h_i)h_i^{\\theta - 1}}\n       {\\Gamma(\\theta)}\n  \\; ;\\;\\; h_i \\geq 0 ,\\; \\theta > 0 \\;.\n\\]\nTo put this in mathematical terms, the negative binomial distribution is a poisson-gamma mixture. Notice that a mean of 1 for \\(h\\) corresponds to a mean of 0 for \\(\\varepsilon\\), i.e. we account for some extra zero-centered deviation around \\(\\pmb x_i \\pmb\\beta\\). To put this another way, for \\(y_i \\sim \\mathrm{poisson}(h_i\\lambda_i)\\), if \\(E[h_i] = 1\\) then we can see that \\(E[y_i] = \\lambda_i\\). I.e. \\(E[h_i] = 1\\) is the multiplicative equivalent of \\(E[\\varepsilon] = 0\\) in the additive case. This kind of mixing based on multiplicative heterogeneity which on average leaves the Poisson mean unchanged allows us to increase the variability in the Poisson mean, and in turn, the variability of the response. Intuitively this will lead to overdispersion and to increased probabilities of the occurrence of low counts and of high counts.\nNow we have our latent heterogeneity within the conditional mean of the Poisson model4 we can write the the conditional distribution \\(f(y_i|x_i, h_i) = \\prod^n_{i=1}g(y_i | h_i\\lambda_i)\\) where \\(g\\) is the probability density function of the \\(\\mathrm{poisson}(h_i \\lambda_i)\\) (Gourieroux, 1984). However, since \\(\\varepsilon\\) is an unobserved variable, and therefore so is \\(h\\), we must integrate \\(h\\) out to obtain the conditional distribution of interest\n\\[\nf(y_i|x_i) = P[Y=y_i | \\pmb x_i] = \\int\n  \\frac{\\exp(-h_i\\lambda_i)(h_i\\lambda_i)^{y_i}}\n       {y_i!}\\times\n  \\frac{\\theta^\\theta \\exp(-\\theta h_i)h_i^{\\theta - 1}}\n       {\\Gamma(\\theta)}dh_i\n\\]\nWe will spare the maths5 and take for granted that we get\n\\[\n\\boxed{\n\\begin{align}\n\\textbf{Negative binomial (NB-2)}&: \\quad y_i \\sim \\mathcal{NB}_2\\left(\\lambda_i \\equiv \\mu_i,\\; \\theta \\equiv \\alpha^{-1}\\right) \\\\ \\\\\n\\text{ A poisson-gamma mixture }& \\text{with} \\; y_i \\sim \\mathrm{poisson}(h_i \\lambda_i) \\text{ and } h_i \\sim \\mathrm{gamma}(\\theta, \\theta) .\n\\\\ \\\\ \\\\\nP[Y=y_i | \\pmb x_i]\n  &= \\frac{\\Gamma(y_i + \\theta)}\n          {\\Gamma(y_i + 1)\\Gamma(\\theta)}\n     \\left(\\frac{\\theta}\n              {\\theta + \\mu_i}\n     \\right)^\\theta\n     \\left(1- \\frac{\\theta}\n                  {\\theta + \\mu_i}\n     \\right)^{y_i}\\\\ \\\\\n  &= \\frac{\\Gamma(y_i + 1/\\alpha)}\n          {\\Gamma(y_i + 1)\\Gamma(1/\\alpha)}\n     \\left(\\frac{1}\n                {\\alpha\\mu_i + 1}\n     \\right)^{1/\\alpha}\n     \\left(1- \\frac{1}\n                   {\\alpha \\mu_i + 1}\n     \\right)^{y_i} \\\\ \\\\ \\\\\nE[y_i|\\pmb x_i] &= \\lambda_i = \\mu_i = \\exp(\\pmb x_i\\pmb\\beta)\\\\ \\\\ \\\\\n\\mathrm{Var}[y_i|\\pmb x_i]\n  &= \\mu_i\\left(\\frac{\\mu_i}{\\theta} + 1 \\right)\\\\\n  &= \\mu_i\\big(\\alpha \\mu_i + 1\\big)\\\\ \\\\ \\\\\n\\text{for } \\; y_i \\in \\mathbb{Z}^{0+}, \\; \\theta > 0, \\; \\text{and }&\\text{heterogeneity/overdispersion parameter } \\alpha = 1/\\theta > 0.\\quad\n\\end{align}\n}\n\\tag{2.1}\\]\nThis is the NB-2 parameterization of the negative binomial model (named by CT, 1986 in reference to the quadratic exponent of \\(\\mu\\) in the conditional variance function) — the standard parameterization for NB regression. Notice that this parameterization, resulting from the inclusion of a latent heterogeneity effect, relaxes the equidispersion restriction of the Poisson model while preserving the same conditional mean.\nThe Poisson model is nested within the NB2 model as the boundary case when \\(\\alpha = 0\\). So is the geometric model when \\(\\alpha = 1\\).\nThe variance to mean ratio describes the ‘extra-Poisson dispersion’ (overdispersion). Here we have \\[\n\\frac{\\text{Variance}}{\\text{Mean}} = \\frac{\\mu_i(\\alpha\\mu_i + 1)}{\\mu_i} = \\alpha\\mu_i + 1\n\\]\nNotice that the overdispersion depends on \\(i\\), i.e. it is variable. This is why the NB2 parameterization is sometimes called the variable overdisperison NB.\n\n\n\n\n\n\nDifferent names for the same thing\n\n\n\nThe negative binomial PMF is found in many different forms. \\(\\lambda\\) or \\(\\mu\\), \\(\\alpha\\) or \\(1/\\theta\\), \\(\\alpha\\) could be called \\(\\phi\\) and \\(\\theta\\) could be \\(\\nu\\). Some authors prefer to leave the gamma scale parameter, \\(\\theta\\), as it is. In this form the heterogeneity parameter (\\(\\theta\\)) is inversely related to the amount of Poisson overdispersion in the data. Most contemporary statisticians, however, prefer a direct relationship. Hence the use of \\(\\alpha = 1/\\theta\\).\n\n\n\n\n\n\n\n\nSummary\n\n\n\nHere we saw the Negative Binomial (NB-2 paramaterization) is a Poisson model with latent heterogeneity distributed as single-parameter gamma. This gamma noise overcomes the equidispersion limitation of the Poisson model, accomodating overdispersed or correlated counts through the addition of an overdispersion parameter in the NB variance, but still retain the same conditional mean. The distribution is parameterized by its mean \\(\\mu_i = \\lambda_i\\) and heterogeneity parameter \\(\\alpha\\) (aka. overdispersion parameter) which is the inverse of the gamma noise parameter \\(\\theta\\). This parameterization is intuitive in the context of regression for overdispersed counts, however many other parameterizations exist.\n\n\n\n\n\n\n\n\nPonder\n\n\n\nHere we distributed our latent heterogeneity term as gamma. What is special about the gamma distribution? What would happen if we used a different distribution? The answers could be in Hilbe (2011)."
  },
  {
    "objectID": "ch_modelling_counts/regression_count_data.html#sec-NB1",
    "href": "ch_modelling_counts/regression_count_data.html#sec-NB1",
    "title": "2  Modelling counts",
    "section": "2.5 Negative Binomial (NB-1)",
    "text": "2.5 Negative Binomial (NB-1)\nThe NB1 (aka linear NB, constant dispersion NB) is derived as a Poisson-gamma mixture model, however the manner of derivation differs from the traditional NB2 model. First derived by Evans (1953), it begins with the Poisson distribution\n\\[\ny_i \\sim \\mathrm{Poisson}(\\lambda_i); \\quad\n  P[Y = y_i | \\lambda_i] =\n  \\frac{e^{-\\lambda_i}\\lambda_i^{y_i}}\n       {y_i!}\n\\]\nFor the NB1, we assume the Poisson parameter itself is distributed gamma as\n\\[\n\\lambda_i \\sim \\mathrm{gamma}(\\mu_i, \\delta)\n\\]\nwhere we assign the mean \\(\\mu_i = \\exp(\\pmb x_i \\pmb\\beta)\\) to the shape parameter, and \\(\\delta\\) is the scale parameter.6 7\n\n\n\n\n\n\nThe above is shown as \\(Gamma(\\delta, \\mu_i)\\) in multiple of Hilbe’s textbooks, where delta is still the scale parameter and mu the shape. Is it Gamma(shape, scale) or Gamma(scale, shape)?\n\n\n\nAs such, the expected value of the Poisson parameter is \\(E[\\lambda_i] = \\mu_i/\\delta\\) and the variance is \\(\\mathrm{Var}[\\lambda_i] = \\mu_i/\\delta^2\\). The resulting Poisson-gamma mixture, integrating out \\(\\lambda\\) can be defined as\n\\[\nf(y_i|\\pmb x_i) = \\int^\\infty_0\n  \\frac{e^{-\\lambda_i}\\lambda_i^{y_i}}\n       {y_i!}\n  \\frac{\\delta^{\\mu_i}\\lambda_i^{\\mu_i - 1}}\n       {\\Gamma(\\mu_i)}\n  \\exp(-\\lambda_i\\delta) \\; d\\lambda\n\\]\nSparing the math8 we get\n\\[\n\\boxed{\n\\begin{align}\n\\textbf{Negative binomial (NB-1)}&: \\quad y_i \\sim \\mathcal{NB}_1\\left(\\mu_i,\\; \\delta \\equiv \\alpha^{-1}\\right) \\\\ \\\\\nP[Y=y_i | \\pmb x_i]\n  &= \\frac{\\Gamma(y_i + \\mu_i)}\n          {\\Gamma(y_i + 1)\\Gamma(\\mu_i)}\n     \\left(\\frac{\\delta}\n                {\\delta + 1}\n     \\right)^{\\mu_i}\n     \\left(\\frac{1}\n                   {\\delta + 1}\n     \\right)^{y_i} \\\\ \\\\\n  &= \\frac{\\Gamma(y_i + \\mu_i)}\n          {\\Gamma(y_i + 1)\\Gamma(\\mu_i)}\n     \\left(\\frac{1}\n                {\\alpha + 1}\n     \\right)^{\\mu_i}\n     \\left(\\frac{\\alpha}\n                {\\alpha + 1}\n     \\right)^{y_i} \\\\ \\\\ \\\\\nE[y_i|\\pmb x_i]\n  &= \\frac{\\exp(\\pmb x_i\\pmb\\beta)}\n          {\\delta}\n  = \\frac{\\mu_i}\n          {\\delta}  \n  =  \\alpha \\mu_i\\\\ \\\\\n\\mathrm{Var}[y_i|\\pmb x_i]\n  &= \\frac{\\mu_i (\\delta + 1)}\n          {\\delta^2}\n  =  \\alpha\\mu_i(\\alpha + 1)\\\\ \\\\\n\\text{for } \\; y_i \\in \\mathbb{Z}^{0+}, \\; \\delta > 0, \\; \\text{and }&\\text{ heterogeneity/overdispersion parameter } \\alpha = 1/\\theta > 0.\\quad\n\\end{align}\n}\n\\tag{2.2}\\]\nAgain we have the nested Poisson model as the boundary case when \\(\\alpha = 0\\).\nThe variance to mean ratio, denoting the ‘extra-Poisson dispersion’ (i.e. overdispersion), is\n\\[\n\\frac{\\text{Variance}}{\\text{Mean}} = \\frac{\\mu_i(\\delta + 1)/\\delta^2}{\\mu_i/\\delta} = \\frac{\\delta + 1}{\\delta} = \\alpha + 1\n\\]\nNotice that unlike the NB2 parameterization, in which the overdispersion was variable, here the overdispersion is constant. This is why the NB1 is sometimes called the constant overdispersion NB.\n\n\n\n\n\n\nWhat’s in a parameterization: NB2 vs. NB1 (CT, 1986)\n\n\n\nThe parameterization of the NB model is determined by the parameterization of the gamma heterogeneity distribution. As such, the NB2 and NB1 parameterizations imply different assumptions about the functional form of heteroscedasticity — a point which is not emphasized in the literature — and hence in general will lead to different estimates of \\(\\pmb\\beta\\). The two alternative specifications of the gamma heterogeneity distribution amount to different parameterizations in the univariate model, but where a regression component is present they lead to different models. This difference is also relevant when we consider the test of the null hypothesis that the distribution of Y is Poisson against the alternative that it is negative binomial.\nNote that for the intercept only model \\(\\mu_i = \\beta\\) (i.e. no \\(x\\) variables in the model), if observations are i.i.d., the specific NB parameterization and resulting difference in model form is of no consequence."
  },
  {
    "objectID": "ch_modelling_counts/regression_count_data.html#sec-GenPois",
    "href": "ch_modelling_counts/regression_count_data.html#sec-GenPois",
    "title": "2  Modelling counts",
    "section": "2.6 Generalized Poisson",
    "text": "2.6 Generalized Poisson\nWhen there is overdispersion due to latent heterogeneity, people often assume a gamma mixture of poisson variables. Suppose that is \\(\\varepsilon_i\\) is an unobserved individual heterogeneity factor (e.g. an unobserved covariate), with \\(\\exp(\\varepsilon)\\) following a gamma distribution with mean 1 (i.e. single parameter gamma distribution) and variance \\(\\alpha\\). Now assume the response vector follows a modification of the Poisson model with mean \\(\\lambda^*_i = \\exp(\\pmb x_i \\pmb\\beta + \\varepsilon_i)\\). The result is the well-known negative binomial regression model where \\(\\alpha\\) is a nonnegative parameter, indicating the degree of overdispersion.\nAs alternative to the negative binomial for overdispersed counts we may assume the response follows a generalized poisson (GP) distribution. Originally developed by Consul and Jain (1973), it has since undergone various modifications (the restricted generalized Poisson, three parameterizations of a hybrid generalized Poisson, etc).\nThe generalized poisson model is similar to the negative binomial in that it incorporates an extra heterogeneity parameter.9 However, whereas the negative binomial hetergeneity parameter (\\(\\alpha\\)) is based on the single-parameter gamma distribution (NB2 parameterization; Section 2.4), the heterogeneity parameter employed by the generalized poisson is based on the lognormal distribution.10 This allows modelling of both overdispersed ?and underdispersed data?.\nThere are several different models that are referred to as generalized poisson models.\n\nThe standard parameterization comes from Consul (1989) (detailed in Consul and Famoye, 1992; shown to be a poisson mixture in Joe and Zhu, 2005). In Consul and Famoye (1992) the model is specified to deal with underdispersion to some degree, however it seems like this parameterization has been restricted to overdispersion only (\\(\\delta > 0\\)) in later works (see Joe and Zhu, 2005).\n\n\\[\n\\boxed{\n  \\begin{align}\n    \\textbf{Generalized poisson} & \\text{ (Consul, 1989)}: \\quad\n    y_i \\sim \\mathrm{GenPois}(\\theta_i, \\delta)\n    \\\\\\\\\n    P[Y = y_i | \\pmb x_i, \\pmb\\beta]\n      &= \\theta_i(\\theta_i + \\delta y_i)^{y_i - 1}\n         \\frac{\\exp(-\\theta_i-\\delta y_i)}\n              {y!} \\\\ \\\\\n    E[Y_i|\\theta_i, \\delta]\n      &= \\mu_i = \\frac{\\theta_i}\n                      {1-\\delta} \\\\ \\\\\n    \\mathrm{Var}(Y_i | \\theta_i, \\delta)\n      &= \\frac{\\theta_i}\n              {(1-\\delta)^3} \\\\ \\\\\n      &= \\frac{1}\n              {(1-\\delta)^2} E[y_i] \\\\ \\\\\n      &= \\phi E[y_i]\\\\ \\\\\n  \\text{ for } \\; y_i \\in \\mathbb{Z}^{0+}, \\;\\; \\theta_i > 0, \\;\\; & \\max(-1, -\\theta_i/4) < \\delta < 1, \\; \\text{and}\\\\\n  \\text{overdispersion parame}&\\text{ter } \\phi = 1/(1-\\delta)^2.\\quad\n  \\end{align}\n}\n\\tag{2.3}\\]\nWhen \\(\\delta = 0 \\;\\Leftrightarrow\\; \\phi = 1\\) the GP reduces to the nested Poisson distribution with parameter \\(\\theta_i\\). When \\(\\delta < 0 \\;\\Leftrightarrow\\; \\phi < 1\\) we have underdispersion and for \\(\\delta > 0 \\;\\Leftrightarrow\\; \\phi > 1\\) we have overdispersion.\nConsol (1989) introduce covariates into a regression model based on the GP distirbution via\n\\[\nE[y_i] = \\frac{\\theta_i}{1-\\delta} = \\mu_i = \\exp(\\pmb x_i\\pmb\\beta)\n\\]\nUnder this parameterization the corresponding GP regression model is obtained by subbing \\(\\theta_i = (1-\\delta)\\mu_i\\) into Equation 2.3 to get \\[\nP(Y = y_i | \\pmb x_i, \\pmb \\beta, \\delta)\n  = \\frac{(1-\\delta)\\mu_i \\big[(1 - \\delta)\\mu_i + \\delta y_i \\big]^{y_i - 1} \\exp\\big(-(1-\\delta)\\mu_i - \\delta y_i \\big)}{y!}\n\\]\nfor \\(\\mu_i > 0\\), \\(\\max(-1, -\\theta_i/4) < \\delta \\leq 1\\) and \\(E[y_i] = \\mu_i = \\exp(\\pmb x_i\\pmb\\beta)\\) (Yang, 2007).\n\n\n\n\n\n\n\n\nWrong generalized poisson definition in Hilbe (2011)?\n\n\n\n\n\nThe below is from Hilbe (2011). Note that this is a different definition to that used in Consul and Famoye (1992), Joe and Zhu (2005), and Hardin and Hilbe (2018). Is this an error? Perhaps there is equality between the two and I just don’t see it. I will steer clear of the Hilbe (2011) definition.\n\n\n\n\nThe value \\(\\theta\\) serves as the heterogeneity parameter, analogous to the negative binomial heterogeneity parameter \\(\\alpha\\), and reflects the amount of ‘extra-poisson’ dispersion in the data. As with the NB \\(\\alpha\\), as \\(\\theta\\) approaches zero this parameterization reduces to the Poisson distribution.\n\nAnother well-known parameterization is given in Famoye and Singh (2006) and Winkelmann (2008).\n\\[\n\\boxed{\n  \\begin{align}\n    \\textbf{Generalized poisson} & \\text{ - Famoye and Singh (2006) parameterization} \\\\ \\\\\n    P[Y = y_i | \\mu_i, \\alpha]\n      &= \\left(\n            \\frac{\\mu_i}\n                 {\\alpha\\mu_i + 1}\n          \\right)^{y_i}\n          \\left(\n            \\frac{(\\alpha y_i + 1)^{y_i - 1}}\n                 {y!}\n          \\right)\n          \\exp\\left(\n            \\frac{-\\mu_i(\\alpha y_i + 1)}\n                 {\\alpha \\mu_i + 1}\n          \\right)\n    \\\\ \\\\\n    E[y_i|\\mu_i, \\alpha]\n      &= \\mu_i \\\\ \\\\\n    \\mathrm{Var}[y_i | \\mu_i, \\alpha]\n      &= \\mu_i(1 - \\alpha\\mu_i)^2 \\\\ \\\\\n  \\text{for heterogeneity }&\\text{parameter } \\alpha.\n  \\end{align}\n}\n\\]\nfor heterogeneity parameter \\(\\alpha\\). Again, as \\(\\alpha \\to 0\\), this generalized Poisson distribution is reduced to the Poisson."
  },
  {
    "objectID": "ch_modelling_counts/regression_count_data.html#summary-1",
    "href": "ch_modelling_counts/regression_count_data.html#summary-1",
    "title": "2  Modelling counts",
    "section": "2.7 Summary",
    "text": "2.7 Summary\n\ncol_names <- c(\n  \"Family\",\n  \"Parameterization\", \n  \"Heterogeneity parameter\",\n  \"Nested models\",\n  \"Extra-poisson dispersion\"\n)\ntab <- data.frame() |>  \n  rbind(c(\n    \"Negative Binomial\", \n    \"NB2\", \n    \"\\\\alpha\", \n    \"Poisson ($\\\\alpha = 0)\", \n    \"\"\n  )) \n  # Add more rows here\n\ncolnames(tab) <- col_names"
  },
  {
    "objectID": "ch_modelling_counts/regression_count_data.html#resourcesreferences",
    "href": "ch_modelling_counts/regression_count_data.html#resourcesreferences",
    "title": "2  Modelling counts",
    "section": "2.8 Resources/references",
    "text": "2.8 Resources/references\n\nEvans, 1953\nConsul and Jain, 1973\nBulmer, 1974\nJanardan et al, 1979\nGourieroux, 1984\nCT, 1986\nCT, 2013\nConsul and Famoye, 1992\nJoe and Zhu, 2005\nFamoye and Singh, 2006\nGreene, 2008\nWinkelmann, 2008\nHilbe, 2011\nHardon and Hilbe, 2018\nhttps://www.youtube.com/watch?v=uGKnoAw-PFQ\nStatistical Methods Series: Zero-Inflated GLM and GLMM"
  },
  {
    "objectID": "ch_count_models/1_count_models_intro.html#not-sure-where-to-put",
    "href": "ch_count_models/1_count_models_intro.html#not-sure-where-to-put",
    "title": "2  Count models",
    "section": "2.1 Not sure where to put…",
    "text": "2.1 Not sure where to put…\nA GLM model contains 3 main components\n\nThe response distribution - we need to assume a distribution for the response variable \\(y_i\\), e.g. \\(y_i \\sim \\mathrm{poisson}(\\lambda_i)\\).\nThe predictor function - a deterministic function of the covariates and model coefficients.\nA link - between the expected value of the distribution and the predictor function.\n\nNever start with overdispersion or zero-inflation models. First start simple (this is always the Poisson model for count data), fit and validate the simple model and then find solutions to problems. People often think that just because we have many zeros in our data we need to use, or should use, a zero-inflated model. This is not the case - we may have covariates which can explain the excess number of zeros.\nThe Poisson distribution is a maximum-entropy distribution (least informative).\nThe log-link \\(\\mu_i = \\exp(\\eta_i) = \\exp(\\pmb x_i\\pmb\\beta)\\) ensures the the expected values are always positive. This is a nice restriction for count data.\nThroughout this material we talk a lot about hetergeneity parameters, aka overdispersion parameters, aka dispersion parameters. This is not to be confused with the dispersion statistic\ndisp_stat_i = (observed data i - modelled expected value i)/sqrt(modelled var i) = residual i / sqrt(var i)\nsee SMS:ZIGLMAGLMM video @ 24:45."
  },
  {
    "objectID": "ch_count_models/1_count_models_intro.html#poisson",
    "href": "ch_count_models/1_count_models_intro.html#poisson",
    "title": "2  Count models",
    "section": "2.2 Poisson",
    "text": "2.2 Poisson\nFor a regression model \\(Y = \\pmb\\beta\\pmb X + \\epsilon_i\\), the canonical likelihood function when \\(Y\\) is a count variable is the Poisson (\\(Y \\sim Poisson(\\lambda)\\)), with probability mass function\n\\[\nP(Y = y_i |\\pmb x_i) =\n  \\frac{\\exp(-\\lambda_i)\\lambda_i^{y_i}}\n       {\\Gamma(1 + y_i)}\n\\]\nfor \\(E(y_i|\\pmb x_i) = \\lambda_i = \\mu_i = \\exp(\\pmb \\beta \\pmb x_i)\\) and \\(Var(y_i | \\pmb x_i) = \\lambda_i\\). The signature features of the Poisson model are its loglinear conditional mean function \\(\\log E(y_i|\\pmb x_i) = \\log \\mu_i = \\pmb \\beta \\pmb x_i\\) (the log of the conditional mean is linear in the parameters), and equal mean and variance \\(Var(y_i | \\pmb x_i) = \\lambda_i\\) which is also called equidispersion since the dispersion \\(\\frac{\\text{variance}}{\\text{mean}} = 1\\).\nHowever, Poisson models tend to be a poor fit in many ecological contexts due to overdispersion. Overdispersion arises naturally due to heterogeneity (e.g. as fish cluster in preferred habitats; as transient schooling species lead to some very large abundance observations), dependence between observations due to spatial and temporal autocorrelation (e.g. dependence of fish abundance within sites and years), and zero-inflation. It may also be due to artifacts of sampling and not measuring or controlling for key covariates influencing local patterns of fish abundance (e.g. time of day, tides, etc). The most popular distribution for overdispersed counts in ecological studies is the negative binomial (NB), which has been shown to appropriately model overdispersion in a range of ecological contexts (Stoklosa et al, 2022)."
  },
  {
    "objectID": "ch_count_models/1_count_models_intro.html#extra-poisson-dispersion",
    "href": "ch_count_models/1_count_models_intro.html#extra-poisson-dispersion",
    "title": "2  Count models",
    "section": "2.3 Extra-poisson dispersion",
    "text": "2.3 Extra-poisson dispersion\nFor the poisson we have \\(E[y_i | \\pmb x_i] = \\mathrm{Var}[y_i | \\pmb x_i]\\). Models which account for ‘extra-poisson dispersion’ do so through the use of an extra parameter such that \\(E[y_i | \\pmb x_i] = \\phi\\mathrm{Var}[y_i | \\pmb x_i]\\), for extra-poisson dispersion parameter \\(\\phi\\)."
  },
  {
    "objectID": "ch_count_models/1_count_models_intro.html#sec-NB2",
    "href": "ch_count_models/1_count_models_intro.html#sec-NB2",
    "title": "2  Count models",
    "section": "2.4 Negative Binomial (NB-2)",
    "text": "2.4 Negative Binomial (NB-2)\nThe derivation on the negative binomial NB2 is usually illustrated as a Poisson model with gamma heterogeneity, where the gamma noise has a mean of 1.1 An intuitive way to think of this is through the introduction of latent heterogeneity2 (an unobserved effect) to the mean of the Poisson model (Greene, 2008).\nRecall our Poisson model of \\(y_i \\sim \\mathrm{poisson}(\\lambda_i)\\) for \\(\\lambda_i = \\mu_i = \\exp(\\pmb x_i \\pmb\\beta)\\)3 which has the property of equidispersion since \\(E[y_i | \\pmb x_i] = \\mathrm{Var}[y_i | \\pmb x_i] = \\lambda_i\\). We will alter this poisson model to account for extra variance in our data, i.e. overdispersion \\(\\mathrm{Var}[y_i | \\pmb x_i] > E[y_i | \\pmb x_i]\\). We can imagine this extra variance stemming from observation-level deviations from the mean dues to an unobserved effect; we will refer to these deviations as latent heterogeneity. Let \\(\\varepsilon\\) represent this latent heterogeneity, then we can re-express the mean as \\(\\mu_i^* = \\exp(\\pmb x_i \\pmb\\beta + \\varepsilon_i)\\). Here \\(\\varepsilon\\) is its own random variable to which we will assign a probability distribution. Now define \\(h_i = \\exp(\\varepsilon_i)\\) such that\n\\[\ny_i \\sim \\mathrm{poisson}(h_i\\lambda_i)\n\\]\nThis is a common step in the derivation of models for overdispersed counts, where the assumed distribution of \\(h_i\\) leads to different models and parameterizations. For the negative binomial (NB2) model we assume that \\(h_i\\) follows a single-parameter gamma distribution\n\\[\nh_i \\sim \\mathrm{gamma}(k = \\theta, \\; \\theta)\n\\]\nwith mean 1 and variance \\(\\alpha = 1/\\theta\\). The probability density of \\(h_i\\) is then\n\\[\nf(h_i) =\n  \\frac{\\theta^\\theta \\exp(-\\theta h_i)h_i^{\\theta - 1}}\n       {\\Gamma(\\theta)}\n  \\; ;\\;\\; h_i \\geq 0 ,\\; \\theta > 0 \\;.\n\\]\nTo put this in mathematical terms, the negative binomial distribution is a poisson-gamma mixture. Notice that a mean of 1 for \\(h\\) corresponds to a mean of 0 for \\(\\varepsilon\\), i.e. we account for some extra zero-centered deviation around \\(\\pmb x_i \\pmb\\beta\\). To put this another way, for \\(y_i \\sim \\mathrm{poisson}(h_i\\lambda_i)\\), if \\(E[h_i] = 1\\) then we can see that \\(E[y_i] = \\lambda_i\\). I.e. \\(E[h_i] = 1\\) is the multiplicative equivalent of \\(E[\\varepsilon] = 0\\) in the additive case. This kind of mixing based on multiplicative heterogeneity which on average leaves the Poisson mean unchanged allows us to increase the variability in the Poisson mean, and in turn, the variability of the response. Intuitively this will lead to overdispersion and to increased probabilities of the occurrence of low counts and of high counts.\nNow we have our latent heterogeneity within the conditional mean of the Poisson model4 we can write the the conditional distribution \\(f(y_i|x_i, h_i) = \\prod^n_{i=1}g(y_i | h_i\\lambda_i)\\) where \\(g\\) is the probability density function of the \\(\\mathrm{poisson}(h_i \\lambda_i)\\) (Gourieroux, 1984). However, since \\(\\varepsilon\\) is an unobserved variable, and therefore so is \\(h\\), we must integrate \\(h\\) out to obtain the conditional distribution of interest\n\\[\nf(y_i|x_i) = P[Y=y_i | \\pmb x_i] = \\int\n  \\frac{\\exp(-h_i\\lambda_i)(h_i\\lambda_i)^{y_i}}\n       {y_i!}\\times\n  \\frac{\\theta^\\theta \\exp(-\\theta h_i)h_i^{\\theta - 1}}\n       {\\Gamma(\\theta)}dh_i\n\\]\nWe will spare the maths5 and take for granted that we get\n\\[\n\\boxed{\n\\begin{align}\n\\textbf{Negative binomial (NB-2)}&: \\quad y_i \\sim \\mathcal{NB}_2\\left(\\lambda_i \\equiv \\mu_i,\\; \\theta \\equiv \\alpha^{-1}\\right) \\\\ \\\\\n\\text{ A poisson-gamma mixture }& \\text{with} \\; y_i \\sim \\mathrm{poisson}(h_i \\lambda_i) \\text{ and } h_i \\sim \\mathrm{gamma}(\\theta, \\theta) .\n\\\\ \\\\ \\\\\nP[Y=y_i | \\pmb x_i]\n  &= \\frac{\\Gamma(y_i + \\theta)}\n          {\\Gamma(y_i + 1)\\Gamma(\\theta)}\n     \\left(\\frac{\\theta}\n              {\\theta + \\mu_i}\n     \\right)^\\theta\n     \\left(1- \\frac{\\theta}\n                  {\\theta + \\mu_i}\n     \\right)^{y_i}\\\\ \\\\\n  &= \\frac{\\Gamma(y_i + 1/\\alpha)}\n          {\\Gamma(y_i + 1)\\Gamma(1/\\alpha)}\n     \\left(\\frac{1}\n                {\\alpha\\mu_i + 1}\n     \\right)^{1/\\alpha}\n     \\left(1- \\frac{1}\n                   {\\alpha \\mu_i + 1}\n     \\right)^{y_i} \\\\ \\\\ \\\\\nE[y_i|\\pmb x_i] &= \\lambda_i = \\mu_i = \\exp(\\pmb x_i\\pmb\\beta)\\\\ \\\\ \\\\\n\\mathrm{Var}[y_i|\\pmb x_i]\n  &= \\mu_i\\left(\\frac{\\mu_i}{\\theta} + 1 \\right)\\\\\n  &= \\mu_i\\big(\\alpha \\mu_i + 1\\big)\\\\ \\\\ \\\\\n\\text{for } \\; y_i \\in \\mathbb{Z}^{0+}, \\; \\theta > 0, \\; \\text{and }&\\text{heterogeneity/overdispersion parameter } \\alpha = 1/\\theta > 0.\\quad\n\\end{align}\n}\n\\tag{2.1}\\]\nThis is the NB-2 parameterization of the negative binomial model (named by CT, 1986 in reference to the quadratic exponent of \\(\\mu\\) in the conditional variance function) — the standard parameterization for NB regression. Notice that this parameterization, resulting from the inclusion of a latent heterogeneity effect, relaxes the equidispersion restriction of the Poisson model while preserving the same conditional mean.\nThe Poisson model is nested within the NB2 model as the boundary case when \\(\\alpha = 0\\). So is the geometric model when \\(\\alpha = 1\\).\nThe variance to mean ratio describes the ‘extra-Poisson dispersion’ (overdispersion). Here we have \\[\n\\frac{\\text{Variance}}{\\text{Mean}} = \\frac{\\mu_i(\\alpha\\mu_i + 1)}{\\mu_i} = \\alpha\\mu_i + 1\n\\]\nNotice that the overdispersion depends on \\(i\\), i.e. it is variable. This is why the NB2 parameterization is sometimes called the variable overdisperison NB.\n\n\n\n\n\n\nDifferent names for the same thing\n\n\n\nThe negative binomial PMF is found in many different forms. \\(\\lambda\\) or \\(\\mu\\), \\(\\alpha\\) or \\(1/\\theta\\), \\(\\alpha\\) could be called \\(\\phi\\) and \\(\\theta\\) could be \\(\\nu\\). Some authors prefer to leave the gamma scale parameter, \\(\\theta\\), as it is. In this form the heterogeneity parameter (\\(\\theta\\)) is inversely related to the amount of Poisson overdispersion in the data. Most contemporary statisticians, however, prefer a direct relationship. Hence the use of \\(\\alpha = 1/\\theta\\).\n\n\n\n\n\n\n\n\nSummary\n\n\n\nHere we saw the Negative Binomial (NB-2 paramaterization) is a Poisson model with latent heterogeneity distributed as single-parameter gamma. This gamma noise overcomes the equidispersion limitation of the Poisson model, accomodating overdispersed or correlated counts through the addition of an overdispersion parameter in the NB variance, but still retain the same conditional mean. The distribution is parameterized by its mean \\(\\mu_i = \\lambda_i\\) and heterogeneity parameter \\(\\alpha\\) (aka. overdispersion parameter) which is the inverse of the gamma noise parameter \\(\\theta\\). This parameterization is intuitive in the context of regression for overdispersed counts, however many other parameterizations exist.\n\n\n\n\n\n\n\n\nPonder\n\n\n\nHere we distributed our latent heterogeneity term as gamma. What is special about the gamma distribution? What would happen if we used a different distribution? The answers could be in Hilbe (2011)."
  },
  {
    "objectID": "ch_count_models/1_count_models_intro.html#sec-NB1",
    "href": "ch_count_models/1_count_models_intro.html#sec-NB1",
    "title": "2  Count models",
    "section": "2.5 Negative Binomial (NB-1)",
    "text": "2.5 Negative Binomial (NB-1)\nThe NB1 (aka linear NB, constant dispersion NB) is derived as a Poisson-gamma mixture model, however the manner of derivation differs from the traditional NB2 model. First derived by Evans (1953), it begins with the Poisson distribution\n\\[\ny_i \\sim \\mathrm{Poisson}(\\lambda_i); \\quad\n  P[Y = y_i | \\lambda_i] =\n  \\frac{e^{-\\lambda_i}\\lambda_i^{y_i}}\n       {y_i!}\n\\]\nFor the NB1, we assume the Poisson parameter itself is distributed gamma as\n\\[\n\\lambda_i \\sim \\mathrm{gamma}(\\mu_i, \\delta)\n\\]\nwhere we assign the mean \\(\\mu_i = \\exp(\\pmb x_i \\pmb\\beta)\\) to the shape parameter, and \\(\\delta\\) is the scale parameter.6 7\n\n\n\n\n\n\nThe above is shown as \\(Gamma(\\delta, \\mu_i)\\) in multiple of Hilbe’s textbooks, where delta is still the scale parameter and mu the shape. Is it Gamma(shape, scale) or Gamma(scale, shape)?\n\n\n\nAs such, the expected value of the Poisson parameter is \\(E[\\lambda_i] = \\mu_i/\\delta\\) and the variance is \\(\\mathrm{Var}[\\lambda_i] = \\mu_i/\\delta^2\\). The resulting Poisson-gamma mixture, integrating out \\(\\lambda\\) can be defined as\n\\[\nf(y_i|\\pmb x_i) = \\int^\\infty_0\n  \\frac{e^{-\\lambda_i}\\lambda_i^{y_i}}\n       {y_i!}\n  \\frac{\\delta^{\\mu_i}\\lambda_i^{\\mu_i - 1}}\n       {\\Gamma(\\mu_i)}\n  \\exp(-\\lambda_i\\delta) \\; d\\lambda\n\\]\nSparing the math8 we get\n\\[\n\\boxed{\n\\begin{align}\n\\textbf{Negative binomial (NB-1)}&: \\quad y_i \\sim \\mathcal{NB}_1\\left(\\mu_i,\\; \\delta \\equiv \\alpha^{-1}\\right) \\\\ \\\\\nP[Y=y_i | \\pmb x_i]\n  &= \\frac{\\Gamma(y_i + \\mu_i)}\n          {\\Gamma(y_i + 1)\\Gamma(\\mu_i)}\n     \\left(\\frac{\\delta}\n                {\\delta + 1}\n     \\right)^{\\mu_i}\n     \\left(\\frac{1}\n                   {\\delta + 1}\n     \\right)^{y_i} \\\\ \\\\\n  &= \\frac{\\Gamma(y_i + \\mu_i)}\n          {\\Gamma(y_i + 1)\\Gamma(\\mu_i)}\n     \\left(\\frac{1}\n                {\\alpha + 1}\n     \\right)^{\\mu_i}\n     \\left(\\frac{\\alpha}\n                {\\alpha + 1}\n     \\right)^{y_i} \\\\ \\\\ \\\\\nE[y_i|\\pmb x_i]\n  &= \\frac{\\exp(\\pmb x_i\\pmb\\beta)}\n          {\\delta}\n  = \\frac{\\mu_i}\n          {\\delta}  \n  =  \\alpha \\mu_i\\\\ \\\\\n\\mathrm{Var}[y_i|\\pmb x_i]\n  &= \\frac{\\mu_i (\\delta + 1)}\n          {\\delta^2}\n  =  \\alpha\\mu_i(\\alpha + 1)\\\\ \\\\\n\\text{for } \\; y_i \\in \\mathbb{Z}^{0+}, \\; \\delta > 0, \\; \\text{and }&\\text{ heterogeneity/overdispersion parameter } \\alpha = 1/\\theta > 0.\\quad\n\\end{align}\n}\n\\tag{2.2}\\]\nAgain we have the nested Poisson model as the boundary case when \\(\\alpha = 0\\).\nThe variance to mean ratio, denoting the ‘extra-Poisson dispersion’ (i.e. overdispersion), is\n\\[\n\\frac{\\text{Variance}}{\\text{Mean}} = \\frac{\\mu_i(\\delta + 1)/\\delta^2}{\\mu_i/\\delta} = \\frac{\\delta + 1}{\\delta} = \\alpha + 1\n\\]\nNotice that unlike the NB2 parameterization, in which the overdispersion was variable, here the overdispersion is constant. This is why the NB1 is sometimes called the constant overdispersion NB.\n\n\n\n\n\n\nWhat’s in a parameterization: NB2 vs. NB1 (CT, 1986)\n\n\n\nThe parameterization of the NB model is determined by the parameterization of the gamma heterogeneity distribution. As such, the NB2 and NB1 parameterizations imply different assumptions about the functional form of heteroscedasticity — a point which is not emphasized in the literature — and hence in general will lead to different estimates of \\(\\pmb\\beta\\). The two alternative specifications of the gamma heterogeneity distribution amount to different parameterizations in the univariate model, but where a regression component is present they lead to different models. This difference is also relevant when we consider the test of the null hypothesis that the distribution of Y is Poisson against the alternative that it is negative binomial.\nNote that for the intercept only model \\(\\mu_i = \\beta\\) (i.e. no \\(x\\) variables in the model), if observations are i.i.d., the specific NB parameterization and resulting difference in model form is of no consequence."
  },
  {
    "objectID": "ch_count_models/1_count_models_intro.html#sec-GenPois",
    "href": "ch_count_models/1_count_models_intro.html#sec-GenPois",
    "title": "2  Count models",
    "section": "2.6 Generalized Poisson",
    "text": "2.6 Generalized Poisson\nWhen there is overdispersion due to latent heterogeneity, people often assume a gamma mixture of poisson variables. Suppose that is \\(\\varepsilon_i\\) is an unobserved individual heterogeneity factor (e.g. an unobserved covariate), with \\(\\exp(\\varepsilon)\\) following a gamma distribution with mean 1 (i.e. single parameter gamma distribution) and variance \\(\\alpha\\). Now assume the response vector follows a modification of the Poisson model with mean \\(\\lambda^*_i = \\exp(\\pmb x_i \\pmb\\beta + \\varepsilon_i)\\). The result is the well-known negative binomial regression model where \\(\\alpha\\) is a nonnegative parameter, indicating the degree of overdispersion.\nAs alternative to the negative binomial for overdispersed counts we may assume the response follows a generalized poisson (GP) distribution. Originally developed by Consul and Jain (1973), it has since undergone various modifications (the restricted generalized Poisson, three parameterizations of a hybrid generalized Poisson, etc).\nThe generalized poisson model is similar to the negative binomial in that it incorporates an extra heterogeneity parameter.9 However, whereas the negative binomial hetergeneity parameter (\\(\\alpha\\)) is based on the single-parameter gamma distribution (NB2 parameterization; Section 2.4), the heterogeneity parameter employed by the generalized poisson is based on the lognormal distribution.10 This allows modelling of both overdispersed ?and underdispersed data?.\nThere are several different models that are referred to as generalized poisson models.\n\nThe standard parameterization comes from Consul (1989) (detailed in Consul and Famoye, 1992; shown to be a poisson mixture in Joe and Zhu, 2005). In Consul and Famoye (1992) the model is specified to deal with underdispersion to some degree, however it seems like this parameterization has been restricted to overdispersion only (\\(\\delta > 0\\)) in later works (see Joe and Zhu, 2005).\n\n\\[\n\\boxed{\n  \\begin{align}\n    \\textbf{Generalized poisson} & \\text{ (Consul, 1989)}: \\quad\n    y_i \\sim \\mathrm{GenPois}(\\theta_i, \\delta)\n    \\\\\\\\\n    P[Y = y_i | \\pmb x_i, \\pmb\\beta]\n      &= \\theta_i(\\theta_i + \\delta y_i)^{y_i - 1}\n         \\frac{\\exp(-\\theta_i-\\delta y_i)}\n              {y!} \\\\ \\\\\n    E[Y_i|\\theta_i, \\delta]\n      &= \\mu_i = \\frac{\\theta_i}\n                      {1-\\delta} \\\\ \\\\\n    \\mathrm{Var}(Y_i | \\theta_i, \\delta)\n      &= \\frac{\\theta_i}\n              {(1-\\delta)^3} \\\\ \\\\\n      &= \\frac{1}\n              {(1-\\delta)^2} E[y_i] \\\\ \\\\\n      &= \\phi E[y_i]\\\\ \\\\\n  \\text{ for } \\; y_i \\in \\mathbb{Z}^{0+}, \\;\\; \\theta_i > 0, \\;\\; & \\max(-1, -\\theta_i/4) < \\delta < 1, \\; \\text{and}\\\\\n  \\text{overdispersion parame}&\\text{ter } \\phi = 1/(1-\\delta)^2.\\quad\n  \\end{align}\n}\n\\tag{2.3}\\]\nWhen \\(\\delta = 0 \\;\\Leftrightarrow\\; \\phi = 1\\) the GP reduces to the nested Poisson distribution with parameter \\(\\theta_i\\). When \\(\\delta < 0 \\;\\Leftrightarrow\\; \\phi < 1\\) we have underdispersion and for \\(\\delta > 0 \\;\\Leftrightarrow\\; \\phi > 1\\) we have overdispersion.\nConsol (1989) introduce covariates into a regression model based on the GP distirbution via\n\\[\nE[y_i] = \\frac{\\theta_i}{1-\\delta} = \\mu_i = \\exp(\\pmb x_i\\pmb\\beta)\n\\]\nUnder this parameterization the corresponding GP regression model is obtained by subbing \\(\\theta_i = (1-\\delta)\\mu_i\\) into Equation 2.3 to get \\[\nP(Y = y_i | \\pmb x_i, \\pmb \\beta, \\delta)\n  = \\frac{(1-\\delta)\\mu_i \\big[(1 - \\delta)\\mu_i + \\delta y_i \\big]^{y_i - 1} \\exp\\big(-(1-\\delta)\\mu_i - \\delta y_i \\big)}{y!}\n\\]\nfor \\(\\mu_i > 0\\), \\(\\max(-1, -\\theta_i/4) < \\delta \\leq 1\\) and \\(E[y_i] = \\mu_i = \\exp(\\pmb x_i\\pmb\\beta)\\) (Yang, 2007).\n\n\n\n\n\n\n\n\nWrong generalized poisson definition in Hilbe (2011)?\n\n\n\n\n\nThe below is from Hilbe (2011). Note that this is a different definition to that used in Consul and Famoye (1992), Joe and Zhu (2005), and Hardin and Hilbe (2018). Is this an error? Perhaps there is equality between the two and I just don’t see it. I will steer clear of the Hilbe (2011) definition.\n\n\n\n\nThe value \\(\\theta\\) serves as the heterogeneity parameter, analogous to the negative binomial heterogeneity parameter \\(\\alpha\\), and reflects the amount of ‘extra-poisson’ dispersion in the data. As with the NB \\(\\alpha\\), as \\(\\theta\\) approaches zero this parameterization reduces to the Poisson distribution.\n\nAnother well-known parameterization is given in Famoye and Singh (2006) and Winkelmann (2008).\n\\[\n\\boxed{\n  \\begin{align}\n    \\textbf{Generalized poisson} & \\text{ - Famoye and Singh (2006) parameterization} \\\\ \\\\\n    P[Y = y_i | \\mu_i, \\alpha]\n      &= \\left(\n            \\frac{\\mu_i}\n                 {\\alpha\\mu_i + 1}\n          \\right)^{y_i}\n          \\left(\n            \\frac{(\\alpha y_i + 1)^{y_i - 1}}\n                 {y!}\n          \\right)\n          \\exp\\left(\n            \\frac{-\\mu_i(\\alpha y_i + 1)}\n                 {\\alpha \\mu_i + 1}\n          \\right)\n    \\\\ \\\\\n    E[y_i|\\mu_i, \\alpha]\n      &= \\mu_i \\\\ \\\\\n    \\mathrm{Var}[y_i | \\mu_i, \\alpha]\n      &= \\mu_i(1 - \\alpha\\mu_i)^2 \\\\ \\\\\n  \\text{for heterogeneity }&\\text{parameter } \\alpha.\n  \\end{align}\n}\n\\]\nfor heterogeneity parameter \\(\\alpha\\). Again, as \\(\\alpha \\to 0\\), this generalized Poisson distribution is reduced to the Poisson."
  },
  {
    "objectID": "ch_count_models/1_count_models_intro.html#summary-1",
    "href": "ch_count_models/1_count_models_intro.html#summary-1",
    "title": "2  Count models",
    "section": "2.7 Summary",
    "text": "2.7 Summary\n\ncol_names <- c(\n  \"Family\",\n  \"Parameterization\", \n  \"Heterogeneity parameter\",\n  \"Nested models\",\n  \"Extra-poisson dispersion\"\n)\ntab <- data.frame() |>  \n  rbind(c(\n    \"Negative Binomial\", \n    \"NB2\", \n    \"\\\\alpha\", \n    \"Poisson ($\\\\alpha = 0)\", \n    \"\"\n  )) \n  # Add more rows here\n\ncolnames(tab) <- col_names"
  },
  {
    "objectID": "ch_count_models/1_count_models_intro.html#resourcesreferences",
    "href": "ch_count_models/1_count_models_intro.html#resourcesreferences",
    "title": "2  Count models",
    "section": "2.8 Resources/references",
    "text": "2.8 Resources/references\n\nEvans, 1953\nConsul and Jain, 1973\nBulmer, 1974\nJanardan et al, 1979\nGourieroux, 1984\nCT, 1986\nCT, 2013\nConsul and Famoye, 1992\nJoe and Zhu, 2005\nFamoye and Singh, 2006\nGreene, 2008\nWinkelmann, 2008\nHilbe, 2011\nHardon and Hilbe, 2018\nhttps://www.youtube.com/watch?v=uGKnoAw-PFQ\nStatistical Methods Series: Zero-Inflated GLM and GLMM"
  },
  {
    "objectID": "ch_count_models/2_poisson.html",
    "href": "ch_count_models/2_poisson.html",
    "title": "3  Poisson",
    "section": "",
    "text": "For a regression model \\(Y = \\pmb\\beta\\pmb X + \\epsilon_i\\), the canonical likelihood function when \\(Y\\) is a count variable is the Poisson (\\(Y \\sim Poisson(\\lambda)\\)), with probability mass function\n\\[\nP(Y = y_i |\\pmb x_i) =\n  \\frac{\\exp(-\\lambda_i)\\lambda_i^{y_i}}\n       {\\Gamma(1 + y_i)}\n\\]\nfor \\(E(y_i|\\pmb x_i) = \\lambda_i = \\mu_i = \\exp(\\pmb \\beta \\pmb x_i)\\) and \\(Var(y_i | \\pmb x_i) = \\lambda_i\\). The signature features of the Poisson model are its loglinear conditional mean function \\(\\log E(y_i|\\pmb x_i) = \\log \\mu_i = \\pmb \\beta \\pmb x_i\\) (the log of the conditional mean is linear in the parameters), and equal mean and variance \\(Var(y_i | \\pmb x_i) = \\lambda_i\\) which is also called equidispersion since the dispersion \\(\\frac{\\text{variance}}{\\text{mean}} = 1\\).\nHowever, Poisson models tend to be a poor fit in many ecological contexts due to overdispersion. Overdispersion arises naturally due to heterogeneity (e.g. as fish cluster in preferred habitats; as transient schooling species lead to some very large abundance observations), dependence between observations due to spatial and temporal autocorrelation (e.g. dependence of fish abundance within sites and years), and zero-inflation. It may also be due to artifacts of sampling and not measuring or controlling for key covariates influencing local patterns of fish abundance (e.g. time of day, tides, etc). The most popular distribution for overdispersed counts in ecological studies is the negative binomial (NB), which has been shown to appropriately model overdispersion in a range of ecological contexts (Stoklosa et al, 2022)."
  },
  {
    "objectID": "ch_count_models/0_home.html#not-sure-where-to-put",
    "href": "ch_count_models/0_home.html#not-sure-where-to-put",
    "title": "Count models",
    "section": "Not sure where to put…",
    "text": "Not sure where to put…\nA GLM model contains 3 main components\n\nThe response distribution - we need to assume a distribution for the response variable \\(y_i\\), e.g. \\(y_i \\sim \\mathrm{poisson}(\\lambda_i)\\).\nThe predictor function - a deterministic function of the covariates and model coefficients.\nA link - between the expected value of the distribution and the predictor function.\n\nNever start with overdispersion or zero-inflation models. First start simple (this is always the Poisson model for count data), fit and validate the simple model and then find solutions to problems. People often think that just because we have many zeros in our data we need to use, or should use, a zero-inflated model. This is not the case - we may have covariates which can explain the excess number of zeros.\nThe Poisson distribution is a maximum-entropy distribution (least informative).\nThe log-link \\(\\mu_i = \\exp(\\eta_i) = \\exp(\\pmb x_i\\pmb\\beta)\\) ensures the the expected values are always positive. This is a nice restriction for count data.\nThroughout this material we talk a lot about hetergeneity parameters, aka overdispersion parameters, aka dispersion parameters. This is not to be confused with the dispersion statistic\ndisp_stat_i = (observed data i - modelled expected value i)/sqrt(modelled var i) = residual i / sqrt(var i)\nsee SMS:ZIGLMAGLMM video @ 24:45."
  },
  {
    "objectID": "ch_count_models/0_home.html#extra-poisson-dispersion",
    "href": "ch_count_models/0_home.html#extra-poisson-dispersion",
    "title": "Count models",
    "section": "Extra-poisson dispersion",
    "text": "Extra-poisson dispersion\nFor the poisson we have \\(E[y_i | \\pmb x_i] = \\mathrm{Var}[y_i | \\pmb x_i]\\). Models which account for ‘extra-poisson dispersion’ do so through the use of an extra parameter such that \\(E[y_i | \\pmb x_i] = \\phi\\mathrm{Var}[y_i | \\pmb x_i]\\), for extra-poisson dispersion parameter \\(\\phi\\)."
  },
  {
    "objectID": "ch_count_models/0_home.html#sec-NB2",
    "href": "ch_count_models/0_home.html#sec-NB2",
    "title": "Count models",
    "section": "Negative Binomial (NB-2)",
    "text": "Negative Binomial (NB-2)\nThe derivation on the negative binomial NB2 is usually illustrated as a Poisson model with gamma heterogeneity, where the gamma noise has a mean of 1.1 An intuitive way to think of this is through the introduction of latent heterogeneity2 (an unobserved effect) to the mean of the Poisson model (Greene, 2008).\nRecall our Poisson model of \\(y_i \\sim \\mathrm{poisson}(\\lambda_i)\\) for \\(\\lambda_i = \\mu_i = \\exp(\\pmb x_i \\pmb\\beta)\\)3 which has the property of equidispersion since \\(E[y_i | \\pmb x_i] = \\mathrm{Var}[y_i | \\pmb x_i] = \\lambda_i\\). We will alter this poisson model to account for extra variance in our data, i.e. overdispersion \\(\\mathrm{Var}[y_i | \\pmb x_i] > E[y_i | \\pmb x_i]\\). We can imagine this extra variance stemming from observation-level deviations from the mean dues to an unobserved effect; we will refer to these deviations as latent heterogeneity. Let \\(\\varepsilon\\) represent this latent heterogeneity, then we can re-express the mean as \\(\\mu_i^* = \\exp(\\pmb x_i \\pmb\\beta + \\varepsilon_i)\\). Here \\(\\varepsilon\\) is its own random variable to which we will assign a probability distribution. Now define \\(h_i = \\exp(\\varepsilon_i)\\) such that\n\\[\ny_i \\sim \\mathrm{poisson}(h_i\\lambda_i)\n\\]\nThis is a common step in the derivation of models for overdispersed counts, where the assumed distribution of \\(h_i\\) leads to different models and parameterizations. For the negative binomial (NB2) model we assume that \\(h_i\\) follows a single-parameter gamma distribution\n\\[\nh_i \\sim \\mathrm{gamma}(k = \\theta, \\; \\theta)\n\\]\nwith mean 1 and variance \\(\\alpha = 1/\\theta\\). The probability density of \\(h_i\\) is then\n\\[\nf(h_i) =\n  \\frac{\\theta^\\theta \\exp(-\\theta h_i)h_i^{\\theta - 1}}\n       {\\Gamma(\\theta)}\n  \\; ;\\;\\; h_i \\geq 0 ,\\; \\theta > 0 \\;.\n\\]\nTo put this in mathematical terms, the negative binomial distribution is a poisson-gamma mixture. Notice that a mean of 1 for \\(h\\) corresponds to a mean of 0 for \\(\\varepsilon\\), i.e. we account for some extra zero-centered deviation around \\(\\pmb x_i \\pmb\\beta\\). To put this another way, for \\(y_i \\sim \\mathrm{poisson}(h_i\\lambda_i)\\), if \\(E[h_i] = 1\\) then we can see that \\(E[y_i] = \\lambda_i\\). I.e. \\(E[h_i] = 1\\) is the multiplicative equivalent of \\(E[\\varepsilon] = 0\\) in the additive case. This kind of mixing based on multiplicative heterogeneity which on average leaves the Poisson mean unchanged allows us to increase the variability in the Poisson mean, and in turn, the variability of the response. Intuitively this will lead to overdispersion and to increased probabilities of the occurrence of low counts and of high counts.\nNow we have our latent heterogeneity within the conditional mean of the Poisson model4 we can write the the conditional distribution \\(f(y_i|x_i, h_i) = \\prod^n_{i=1}g(y_i | h_i\\lambda_i)\\) where \\(g\\) is the probability density function of the \\(\\mathrm{poisson}(h_i \\lambda_i)\\) (Gourieroux, 1984). However, since \\(\\varepsilon\\) is an unobserved variable, and therefore so is \\(h\\), we must integrate \\(h\\) out to obtain the conditional distribution of interest\n\\[\nf(y_i|x_i) = P[Y=y_i | \\pmb x_i] = \\int\n  \\frac{\\exp(-h_i\\lambda_i)(h_i\\lambda_i)^{y_i}}\n       {y_i!}\\times\n  \\frac{\\theta^\\theta \\exp(-\\theta h_i)h_i^{\\theta - 1}}\n       {\\Gamma(\\theta)}dh_i\n\\]\nWe will spare the maths5 and take for granted that we get\n\\[\n\\boxed{\n\\begin{align}\n\\textbf{Negative binomial (NB-2)}&: \\quad y_i \\sim \\mathcal{NB}_2\\left(\\lambda_i \\equiv \\mu_i,\\; \\theta \\equiv \\alpha^{-1}\\right) \\\\ \\\\\n\\text{ A poisson-gamma mixture }& \\text{with} \\; y_i \\sim \\mathrm{poisson}(h_i \\lambda_i) \\text{ and } h_i \\sim \\mathrm{gamma}(\\theta, \\theta) .\n\\\\ \\\\ \\\\\nP[Y=y_i | \\pmb x_i]\n  &= \\frac{\\Gamma(y_i + \\theta)}\n          {\\Gamma(y_i + 1)\\Gamma(\\theta)}\n     \\left(\\frac{\\theta}\n              {\\theta + \\mu_i}\n     \\right)^\\theta\n     \\left(1- \\frac{\\theta}\n                  {\\theta + \\mu_i}\n     \\right)^{y_i}\\\\ \\\\\n  &= \\frac{\\Gamma(y_i + 1/\\alpha)}\n          {\\Gamma(y_i + 1)\\Gamma(1/\\alpha)}\n     \\left(\\frac{1}\n                {\\alpha\\mu_i + 1}\n     \\right)^{1/\\alpha}\n     \\left(1- \\frac{1}\n                   {\\alpha \\mu_i + 1}\n     \\right)^{y_i} \\\\ \\\\ \\\\\nE[y_i|\\pmb x_i] &= \\lambda_i = \\mu_i = \\exp(\\pmb x_i\\pmb\\beta)\\\\ \\\\ \\\\\n\\mathrm{Var}[y_i|\\pmb x_i]\n  &= \\mu_i\\left(\\frac{\\mu_i}{\\theta} + 1 \\right)\\\\\n  &= \\mu_i\\big(\\alpha \\mu_i + 1\\big)\\\\ \\\\ \\\\\n\\text{for } \\; y_i \\in \\mathbb{Z}^{0+}, \\; \\theta > 0, \\; \\text{and }&\\text{heterogeneity/overdispersion parameter } \\alpha = 1/\\theta > 0.\\quad\n\\end{align}\n}\n\\tag{1}\\]\nThis is the NB-2 parameterization of the negative binomial model (named by CT, 1986 in reference to the quadratic exponent of \\(\\mu\\) in the conditional variance function) — the standard parameterization for NB regression. Notice that this parameterization, resulting from the inclusion of a latent heterogeneity effect, relaxes the equidispersion restriction of the Poisson model while preserving the same conditional mean.\nThe Poisson model is nested within the NB2 model as the boundary case when \\(\\alpha = 0\\). So is the geometric model when \\(\\alpha = 1\\).\nThe variance to mean ratio describes the ‘extra-Poisson dispersion’ (overdispersion). Here we have \\[\n\\frac{\\text{Variance}}{\\text{Mean}} = \\frac{\\mu_i(\\alpha\\mu_i + 1)}{\\mu_i} = \\alpha\\mu_i + 1\n\\]\nNotice that the overdispersion depends on \\(i\\), i.e. it is variable. This is why the NB2 parameterization is sometimes called the variable overdisperison NB.\n\n\n\n\n\n\nDifferent names for the same thing\n\n\n\nThe negative binomial PMF is found in many different forms. \\(\\lambda\\) or \\(\\mu\\), \\(\\alpha\\) or \\(1/\\theta\\), \\(\\alpha\\) could be called \\(\\phi\\) and \\(\\theta\\) could be \\(\\nu\\). Some authors prefer to leave the gamma scale parameter, \\(\\theta\\), as it is. In this form the heterogeneity parameter (\\(\\theta\\)) is inversely related to the amount of Poisson overdispersion in the data. Most contemporary statisticians, however, prefer a direct relationship. Hence the use of \\(\\alpha = 1/\\theta\\).\n\n\n\n\n\n\n\n\nSummary\n\n\n\nHere we saw the Negative Binomial (NB-2 paramaterization) is a Poisson model with latent heterogeneity distributed as single-parameter gamma. This gamma noise overcomes the equidispersion limitation of the Poisson model, accomodating overdispersed or correlated counts through the addition of an overdispersion parameter in the NB variance, but still retain the same conditional mean. The distribution is parameterized by its mean \\(\\mu_i = \\lambda_i\\) and heterogeneity parameter \\(\\alpha\\) (aka. overdispersion parameter) which is the inverse of the gamma noise parameter \\(\\theta\\). This parameterization is intuitive in the context of regression for overdispersed counts, however many other parameterizations exist.\n\n\n\n\n\n\n\n\nPonder\n\n\n\nHere we distributed our latent heterogeneity term as gamma. What is special about the gamma distribution? What would happen if we used a different distribution? The answers could be in Hilbe (2011)."
  },
  {
    "objectID": "ch_count_models/0_home.html#sec-NB1",
    "href": "ch_count_models/0_home.html#sec-NB1",
    "title": "Count models",
    "section": "Negative Binomial (NB-1)",
    "text": "Negative Binomial (NB-1)\nThe NB1 (aka linear NB, constant dispersion NB) is derived as a Poisson-gamma mixture model, however the manner of derivation differs from the traditional NB2 model. First derived by Evans (1953), it begins with the Poisson distribution\n\\[\ny_i \\sim \\mathrm{Poisson}(\\lambda_i); \\quad\n  P[Y = y_i | \\lambda_i] =\n  \\frac{e^{-\\lambda_i}\\lambda_i^{y_i}}\n       {y_i!}\n\\]\nFor the NB1, we assume the Poisson parameter itself is distributed gamma as\n\\[\n\\lambda_i \\sim \\mathrm{gamma}(\\mu_i, \\delta)\n\\]\nwhere we assign the mean \\(\\mu_i = \\exp(\\pmb x_i \\pmb\\beta)\\) to the shape parameter, and \\(\\delta\\) is the scale parameter.6 7\n\n\n\n\n\n\nThe above is shown as \\(Gamma(\\delta, \\mu_i)\\) in multiple of Hilbe’s textbooks, where delta is still the scale parameter and mu the shape. Is it Gamma(shape, scale) or Gamma(scale, shape)?\n\n\n\nAs such, the expected value of the Poisson parameter is \\(E[\\lambda_i] = \\mu_i/\\delta\\) and the variance is \\(\\mathrm{Var}[\\lambda_i] = \\mu_i/\\delta^2\\). The resulting Poisson-gamma mixture, integrating out \\(\\lambda\\) can be defined as\n\\[\nf(y_i|\\pmb x_i) = \\int^\\infty_0\n  \\frac{e^{-\\lambda_i}\\lambda_i^{y_i}}\n       {y_i!}\n  \\frac{\\delta^{\\mu_i}\\lambda_i^{\\mu_i - 1}}\n       {\\Gamma(\\mu_i)}\n  \\exp(-\\lambda_i\\delta) \\; d\\lambda\n\\]\nSparing the math8 we get\n\\[\n\\boxed{\n\\begin{align}\n\\textbf{Negative binomial (NB-1)}&: \\quad y_i \\sim \\mathcal{NB}_1\\left(\\mu_i,\\; \\delta \\equiv \\alpha^{-1}\\right) \\\\ \\\\\nP[Y=y_i | \\pmb x_i]\n  &= \\frac{\\Gamma(y_i + \\mu_i)}\n          {\\Gamma(y_i + 1)\\Gamma(\\mu_i)}\n     \\left(\\frac{\\delta}\n                {\\delta + 1}\n     \\right)^{\\mu_i}\n     \\left(\\frac{1}\n                   {\\delta + 1}\n     \\right)^{y_i} \\\\ \\\\\n  &= \\frac{\\Gamma(y_i + \\mu_i)}\n          {\\Gamma(y_i + 1)\\Gamma(\\mu_i)}\n     \\left(\\frac{1}\n                {\\alpha + 1}\n     \\right)^{\\mu_i}\n     \\left(\\frac{\\alpha}\n                {\\alpha + 1}\n     \\right)^{y_i} \\\\ \\\\ \\\\\nE[y_i|\\pmb x_i]\n  &= \\frac{\\exp(\\pmb x_i\\pmb\\beta)}\n          {\\delta}\n  = \\frac{\\mu_i}\n          {\\delta}  \n  =  \\alpha \\mu_i\\\\ \\\\\n\\mathrm{Var}[y_i|\\pmb x_i]\n  &= \\frac{\\mu_i (\\delta + 1)}\n          {\\delta^2}\n  =  \\alpha\\mu_i(\\alpha + 1)\\\\ \\\\\n\\text{for } \\; y_i \\in \\mathbb{Z}^{0+}, \\; \\delta > 0, \\; \\text{and }&\\text{ heterogeneity/overdispersion parameter } \\alpha = 1/\\theta > 0.\\quad\n\\end{align}\n}\n\\tag{2}\\]\nAgain we have the nested Poisson model as the boundary case when \\(\\alpha = 0\\).\nThe variance to mean ratio, denoting the ‘extra-Poisson dispersion’ (i.e. overdispersion), is\n\\[\n\\frac{\\text{Variance}}{\\text{Mean}} = \\frac{\\mu_i(\\delta + 1)/\\delta^2}{\\mu_i/\\delta} = \\frac{\\delta + 1}{\\delta} = \\alpha + 1\n\\]\nNotice that unlike the NB2 parameterization, in which the overdispersion was variable, here the overdispersion is constant. This is why the NB1 is sometimes called the constant overdispersion NB.\n\n\n\n\n\n\nWhat’s in a parameterization: NB2 vs. NB1 (CT, 1986)\n\n\n\nThe parameterization of the NB model is determined by the parameterization of the gamma heterogeneity distribution. As such, the NB2 and NB1 parameterizations imply different assumptions about the functional form of heteroscedasticity — a point which is not emphasized in the literature — and hence in general will lead to different estimates of \\(\\pmb\\beta\\). The two alternative specifications of the gamma heterogeneity distribution amount to different parameterizations in the univariate model, but where a regression component is present they lead to different models. This difference is also relevant when we consider the test of the null hypothesis that the distribution of Y is Poisson against the alternative that it is negative binomial.\nNote that for the intercept only model \\(\\mu_i = \\beta\\) (i.e. no \\(x\\) variables in the model), if observations are i.i.d., the specific NB parameterization and resulting difference in model form is of no consequence."
  },
  {
    "objectID": "ch_count_models/0_home.html#sec-GenPois",
    "href": "ch_count_models/0_home.html#sec-GenPois",
    "title": "Count models",
    "section": "Generalized Poisson",
    "text": "Generalized Poisson\nWhen there is overdispersion due to latent heterogeneity, people often assume a gamma mixture of poisson variables. Suppose that is \\(\\varepsilon_i\\) is an unobserved individual heterogeneity factor (e.g. an unobserved covariate), with \\(\\exp(\\varepsilon)\\) following a gamma distribution with mean 1 (i.e. single parameter gamma distribution) and variance \\(\\alpha\\). Now assume the response vector follows a modification of the Poisson model with mean \\(\\lambda^*_i = \\exp(\\pmb x_i \\pmb\\beta + \\varepsilon_i)\\). The result is the well-known negative binomial regression model where \\(\\alpha\\) is a nonnegative parameter, indicating the degree of overdispersion.\nAs alternative to the negative binomial for overdispersed counts we may assume the response follows a generalized poisson (GP) distribution. Originally developed by Consul and Jain (1973), it has since undergone various modifications (the restricted generalized Poisson, three parameterizations of a hybrid generalized Poisson, etc).\nThe generalized poisson model is similar to the negative binomial in that it incorporates an extra heterogeneity parameter.1 However, whereas the negative binomial hetergeneity parameter (\\(\\alpha\\)) is based on the single-parameter gamma distribution (NB2 parameterization; ?sec-NB2), the heterogeneity parameter employed by the generalized poisson is based on the lognormal distribution.2 This allows modelling of both overdispersed ?and underdispersed data?.\nThere are several different models that are referred to as generalized poisson models.\n\nThe standard parameterization comes from Consul (1989) (detailed in Consul and Famoye, 1992; shown to be a poisson mixture in Joe and Zhu, 2005). In Consul and Famoye (1992) the model is specified to deal with underdispersion to some degree, however it seems like this parameterization has been restricted to overdispersion only (\\(\\delta > 0\\)) in later works (see Joe and Zhu, 2005).\n\n\\[\n\\boxed{\n  \\begin{align}\n    \\textbf{Generalized poisson} & \\text{ (Consul, 1989)}: \\quad\n    y_i \\sim \\mathrm{GenPois}(\\theta_i, \\delta)\n    \\\\\\\\\n    P[Y = y_i | \\pmb x_i, \\pmb\\beta]\n      &= \\theta_i(\\theta_i + \\delta y_i)^{y_i - 1}\n         \\frac{\\exp(-\\theta_i-\\delta y_i)}\n              {y!} \\\\ \\\\\n    E[Y_i|\\theta_i, \\delta]\n      &= \\mu_i = \\frac{\\theta_i}\n                      {1-\\delta} \\\\ \\\\\n    \\mathrm{Var}(Y_i | \\theta_i, \\delta)\n      &= \\frac{\\theta_i}\n              {(1-\\delta)^3} \\\\ \\\\\n      &= \\frac{1}\n              {(1-\\delta)^2} E[y_i] \\\\ \\\\\n      &= \\phi E[y_i]\\\\ \\\\\n  \\text{ for } \\; y_i \\in \\mathbb{Z}^{0+}, \\;\\; \\theta_i > 0, \\;\\; & \\max(-1, -\\theta_i/4) < \\delta < 1, \\; \\text{and}\\\\\n  \\text{overdispersion parame}&\\text{ter } \\phi = 1/(1-\\delta)^2.\\quad\n  \\end{align}\n}\n\\tag{1}\\]\nWhen \\(\\delta = 0 \\;\\Leftrightarrow\\; \\phi = 1\\) the GP reduces to the nested Poisson distribution with parameter \\(\\theta_i\\). When \\(\\delta < 0 \\;\\Leftrightarrow\\; \\phi < 1\\) we have underdispersion and for \\(\\delta > 0 \\;\\Leftrightarrow\\; \\phi > 1\\) we have overdispersion.\nConsol (1989) introduce covariates into a regression model based on the GP distirbution via\n\\[\nE[y_i] = \\frac{\\theta_i}{1-\\delta} = \\mu_i = \\exp(\\pmb x_i\\pmb\\beta)\n\\]\nUnder this parameterization the corresponding GP regression model is obtained by subbing \\(\\theta_i = (1-\\delta)\\mu_i\\) into Equation 1 to get \\[\nP(Y = y_i | \\pmb x_i, \\pmb \\beta, \\delta)\n  = \\frac{(1-\\delta)\\mu_i \\big[(1 - \\delta)\\mu_i + \\delta y_i \\big]^{y_i - 1} \\exp\\big(-(1-\\delta)\\mu_i - \\delta y_i \\big)}{y!}\n\\]\nfor \\(\\mu_i > 0\\), \\(\\max(-1, -\\theta_i/4) < \\delta \\leq 1\\) and \\(E[y_i] = \\mu_i = \\exp(\\pmb x_i\\pmb\\beta)\\) (Yang, 2007).\n\n\n\n\n\n\n\n\nWrong generalized poisson definition in Hilbe (2011)?\n\n\n\n\n\nThe below is from Hilbe (2011). Note that this is a different definition to that used in Consul and Famoye (1992), Joe and Zhu (2005), and Hardin and Hilbe (2018). Is this an error? Perhaps there is equality between the two and I just don’t see it. I will steer clear of the Hilbe (2011) definition.\n\n\n\n\nThe value \\(\\theta\\) serves as the heterogeneity parameter, analogous to the negative binomial heterogeneity parameter \\(\\alpha\\), and reflects the amount of ‘extra-poisson’ dispersion in the data. As with the NB \\(\\alpha\\), as \\(\\theta\\) approaches zero this parameterization reduces to the Poisson distribution.\n\nAnother well-known parameterization is given in Famoye and Singh (2006) and Winkelmann (2008).\n\\[\n\\boxed{\n  \\begin{align}\n    \\textbf{Generalized poisson} & \\text{ - Famoye and Singh (2006) parameterization} \\\\ \\\\\n    P[Y = y_i | \\mu_i, \\alpha]\n      &= \\left(\n            \\frac{\\mu_i}\n                 {\\alpha\\mu_i + 1}\n          \\right)^{y_i}\n          \\left(\n            \\frac{(\\alpha y_i + 1)^{y_i - 1}}\n                 {y!}\n          \\right)\n          \\exp\\left(\n            \\frac{-\\mu_i(\\alpha y_i + 1)}\n                 {\\alpha \\mu_i + 1}\n          \\right)\n    \\\\ \\\\\n    E[y_i|\\mu_i, \\alpha]\n      &= \\mu_i \\\\ \\\\\n    \\mathrm{Var}[y_i | \\mu_i, \\alpha]\n      &= \\mu_i(1 - \\alpha\\mu_i)^2 \\\\ \\\\\n  \\text{for heterogeneity }&\\text{parameter } \\alpha.\n  \\end{align}\n}\n\\]\nfor heterogeneity parameter \\(\\alpha\\). Again, as \\(\\alpha \\to 0\\), this generalized Poisson distribution is reduced to the Poisson."
  },
  {
    "objectID": "ch_count_models/0_home.html#summary-1",
    "href": "ch_count_models/0_home.html#summary-1",
    "title": "Count models",
    "section": "Summary",
    "text": "Summary\n\ncol_names <- c(\n  \"Family\",\n  \"Parameterization\", \n  \"Heterogeneity parameter\",\n  \"Nested models\",\n  \"Extra-poisson dispersion\"\n)\ntab <- data.frame() |>  \n  rbind(c(\n    \"Negative Binomial\", \n    \"NB2\", \n    \"\\\\alpha\", \n    \"Poisson ($\\\\alpha = 0)\", \n    \"\"\n  )) \n  # Add more rows here\n\ncolnames(tab) <- col_names"
  },
  {
    "objectID": "ch_count_models/0_home.html#resourcesreferences",
    "href": "ch_count_models/0_home.html#resourcesreferences",
    "title": "Count models",
    "section": "Resources/references",
    "text": "Resources/references\n\nEvans, 1953\nConsul and Jain, 1973\nBulmer, 1974\nJanardan et al, 1979\nGourieroux, 1984\nCT, 1986\nCT, 2013\nConsul and Famoye, 1992\nJoe and Zhu, 2005\nFamoye and Singh, 2006\nGreene, 2008\nWinkelmann, 2008\nHilbe, 2011\nHardon and Hilbe, 2018\nhttps://www.youtube.com/watch?v=uGKnoAw-PFQ\nStatistical Methods Series: Zero-Inflated GLM and GLMM"
  },
  {
    "objectID": "ch_count_models/0_home.html#summary",
    "href": "ch_count_models/0_home.html#summary",
    "title": "Count models",
    "section": "Summary",
    "text": "Summary\n\ncol_names <- c(\n  \"Family\",\n  \"Parameterization\", \n  \"Heterogeneity parameter\",\n  \"Nested models\",\n  \"Extra-poisson dispersion\"\n)\ntab <- data.frame() |>  \n  rbind(c(\n    \"Negative Binomial\", \n    \"NB2\", \n    \"\\\\alpha\", \n    \"Poisson ($\\\\alpha = 0)\", \n    \"\"\n  )) \n  # Add more rows here\n\ncolnames(tab) <- col_names"
  },
  {
    "objectID": "count-models/2_poisson.html",
    "href": "count-models/2_poisson.html",
    "title": "3  Poisson",
    "section": "",
    "text": "For a regression model \\(Y = \\pmb\\beta\\pmb X + \\epsilon_i\\), the canonical likelihood function when \\(Y\\) is a count variable is the Poisson (\\(Y \\sim Poisson(\\lambda)\\)), with probability mass function\n\\[\nP(Y = y_i |\\pmb x_i) =\n  \\frac{\\exp(-\\lambda_i)\\lambda_i^{y_i}}\n       {\\Gamma(1 + y_i)}\n\\]\nfor \\(E(y_i|\\pmb x_i) = \\lambda_i = \\mu_i = \\exp(\\pmb \\beta \\pmb x_i)\\) and \\(Var(y_i | \\pmb x_i) = \\lambda_i\\). The signature features of the Poisson model are its loglinear conditional mean function \\(\\log E(y_i|\\pmb x_i) = \\log \\mu_i = \\pmb \\beta \\pmb x_i\\) (the log of the conditional mean is linear in the parameters), and equal mean and variance \\(Var(y_i | \\pmb x_i) = \\lambda_i\\) which is also called equidispersion since the dispersion \\(\\frac{\\text{variance}}{\\text{mean}} = 1\\).\nHowever, Poisson models tend to be a poor fit in many ecological contexts due to overdispersion. Overdispersion arises naturally due to heterogeneity (e.g. as fish cluster in preferred habitats; as transient schooling species lead to some very large abundance observations), dependence between observations due to spatial and temporal autocorrelation (e.g. dependence of fish abundance within sites and years), and zero-inflation. It may also be due to artifacts of sampling and not measuring or controlling for key covariates influencing local patterns of fish abundance (e.g. time of day, tides, etc). The most popular distribution for overdispersed counts in ecological studies is the negative binomial (NB), which has been shown to appropriately model overdispersion in a range of ecological contexts (Stoklosa et al, 2022)."
  },
  {
    "objectID": "count-models/4_negbin.html#sec-NB1",
    "href": "count-models/4_negbin.html#sec-NB1",
    "title": "5  Negative Binomial (NB-2)",
    "section": "5.1 Negative Binomial (NB-1)",
    "text": "5.1 Negative Binomial (NB-1)\nThe NB1 (aka linear NB, constant dispersion NB) is derived as a Poisson-gamma mixture model, however the manner of derivation differs from the traditional NB2 model. First derived by Evans (1953), it begins with the Poisson distribution\n\\[\ny_i \\sim \\mathrm{Poisson}(\\lambda_i); \\quad\n  P[Y = y_i | \\lambda_i] =\n  \\frac{e^{-\\lambda_i}\\lambda_i^{y_i}}\n       {y_i!}\n\\]\nFor the NB1, we assume the Poisson parameter itself is distributed gamma as\n\\[\n\\lambda_i \\sim \\mathrm{gamma}(\\mu_i, \\delta)\n\\]\nwhere we assign the mean \\(\\mu_i = \\exp(\\pmb x_i \\pmb\\beta)\\) to the shape parameter, and \\(\\delta\\) is the scale parameter.6 7\n\n\n\n\n\n\nThe above is shown as \\(Gamma(\\delta, \\mu_i)\\) in multiple of Hilbe’s textbooks, where delta is still the scale parameter and mu the shape. Is it Gamma(shape, scale) or Gamma(scale, shape)?\n\n\n\nAs such, the expected value of the Poisson parameter is \\(E[\\lambda_i] = \\mu_i/\\delta\\) and the variance is \\(\\mathrm{Var}[\\lambda_i] = \\mu_i/\\delta^2\\). The resulting Poisson-gamma mixture, integrating out \\(\\lambda\\) can be defined as\n\\[\nf(y_i|\\pmb x_i) = \\int^\\infty_0\n  \\frac{e^{-\\lambda_i}\\lambda_i^{y_i}}\n       {y_i!}\n  \\frac{\\delta^{\\mu_i}\\lambda_i^{\\mu_i - 1}}\n       {\\Gamma(\\mu_i)}\n  \\exp(-\\lambda_i\\delta) \\; d\\lambda\n\\]\nSparing the math8 we get\n\\[\n\\boxed{\n\\begin{align}\n\\textbf{Negative binomial (NB-1)}&: \\quad y_i \\sim \\mathcal{NB}_1\\left(\\mu_i,\\; \\delta \\equiv \\alpha^{-1}\\right) \\\\ \\\\\nP[Y=y_i | \\pmb x_i]\n  &= \\frac{\\Gamma(y_i + \\mu_i)}\n          {\\Gamma(y_i + 1)\\Gamma(\\mu_i)}\n     \\left(\\frac{\\delta}\n                {\\delta + 1}\n     \\right)^{\\mu_i}\n     \\left(\\frac{1}\n                   {\\delta + 1}\n     \\right)^{y_i} \\\\ \\\\\n  &= \\frac{\\Gamma(y_i + \\mu_i)}\n          {\\Gamma(y_i + 1)\\Gamma(\\mu_i)}\n     \\left(\\frac{1}\n                {\\alpha + 1}\n     \\right)^{\\mu_i}\n     \\left(\\frac{\\alpha}\n                {\\alpha + 1}\n     \\right)^{y_i} \\\\ \\\\ \\\\\nE[y_i|\\pmb x_i]\n  &= \\frac{\\exp(\\pmb x_i\\pmb\\beta)}\n          {\\delta}\n  = \\frac{\\mu_i}\n          {\\delta}  \n  =  \\alpha \\mu_i\\\\ \\\\\n\\mathrm{Var}[y_i|\\pmb x_i]\n  &= \\frac{\\mu_i (\\delta + 1)}\n          {\\delta^2}\n  =  \\alpha\\mu_i(\\alpha + 1)\\\\ \\\\\n\\text{for } \\; y_i \\in \\mathbb{Z}^{0+}, \\; \\delta > 0, \\; \\text{and }&\\text{ heterogeneity/overdispersion parameter } \\alpha = 1/\\theta > 0.\\quad\n\\end{align}\n}\n\\tag{5.2}\\]\nAgain we have the nested Poisson model as the boundary case when \\(\\alpha = 0\\).\nThe variance to mean ratio, denoting the ‘extra-Poisson dispersion’ (i.e. overdispersion), is\n\\[\n\\frac{\\text{Variance}}{\\text{Mean}} = \\frac{\\mu_i(\\delta + 1)/\\delta^2}{\\mu_i/\\delta} = \\frac{\\delta + 1}{\\delta} = \\alpha + 1\n\\]\nNotice that unlike the NB2 parameterization, in which the overdispersion was variable, here the overdispersion is constant. This is why the NB1 is sometimes called the constant overdispersion NB.\n\n\n\n\n\n\nWhat’s in a parameterization: NB2 vs. NB1 (CT, 1986)\n\n\n\nThe parameterization of the NB model is determined by the parameterization of the gamma heterogeneity distribution. As such, the NB2 and NB1 parameterizations imply different assumptions about the functional form of heteroscedasticity — a point which is not emphasized in the literature — and hence in general will lead to different estimates of \\(\\pmb\\beta\\). The two alternative specifications of the gamma heterogeneity distribution amount to different parameterizations in the univariate model, but where a regression component is present they lead to different models. This difference is also relevant when we consider the test of the null hypothesis that the distribution of Y is Poisson against the alternative that it is negative binomial.\nNote that for the intercept only model \\(\\mu_i = \\beta\\) (i.e. no \\(x\\) variables in the model), if observations are i.i.d., the specific NB parameterization and resulting difference in model form is of no consequence."
  },
  {
    "objectID": "count-models/5_genpois.html#summary",
    "href": "count-models/5_genpois.html#summary",
    "title": "6  Generalized Poisson",
    "section": "6.1 Summary",
    "text": "6.1 Summary\n\ncol_names <- c(\n  \"Family\",\n  \"Parameterization\", \n  \"Heterogeneity parameter\",\n  \"Nested models\",\n  \"Extra-poisson dispersion\"\n)\ntab <- data.frame() |>  \n  rbind(c(\n    \"Negative Binomial\", \n    \"NB2\", \n    \"\\\\alpha\", \n    \"Poisson ($\\\\alpha = 0)\", \n    \"\"\n  )) \n  # Add more rows here\n\ncolnames(tab) <- col_names"
  },
  {
    "objectID": "ch/1_intro.html#not-sure-where-to-put",
    "href": "ch/1_intro.html#not-sure-where-to-put",
    "title": "1  Intro",
    "section": "1.1 Not sure where to put…",
    "text": "1.1 Not sure where to put…\nA GLM model contains 3 main components\n\nThe response distribution - we need to assume a distribution for the response variable \\(y_i\\), e.g. \\(y_i \\sim \\mathrm{poisson}(\\lambda_i)\\).\nThe predictor function - a deterministic function of the covariates and model coefficients.\nA link - between the expected value of the distribution and the predictor function.\n\nNever start with overdispersion or zero-inflation models. First start simple (this is always the Poisson model for count data), fit and validate the simple model and then find solutions to problems. People often think that just because we have many zeros in our data we need to use, or should use, a zero-inflated model. This is not the case - we may have covariates which can explain the excess number of zeros.\nThe Poisson distribution is a maximum-entropy distribution (least informative).\nThe log-link \\(\\mu_i = \\exp(\\eta_i) = \\exp(\\pmb x_i\\pmb\\beta)\\) ensures the the expected values are always positive. This is a nice restriction for count data.\nThroughout this material we talk a lot about hetergeneity parameters, aka overdispersion parameters, aka dispersion parameters. This is not to be confused with the dispersion statistic\ndisp_stat_i = (observed data i - modelled expected value i)/sqrt(modelled var i) = residual i / sqrt(var i)\nsee SMS:ZIGLMAGLMM video @ 24:45."
  },
  {
    "objectID": "ch/1_intro.html#extra-poisson-dispersion",
    "href": "ch/1_intro.html#extra-poisson-dispersion",
    "title": "1  Intro",
    "section": "1.2 Extra-poisson dispersion",
    "text": "1.2 Extra-poisson dispersion\nFor the poisson we have \\(E[y_i | \\pmb x_i] = \\mathrm{Var}[y_i | \\pmb x_i]\\). Models which account for ‘extra-poisson dispersion’ do so through the use of an extra parameter such that \\(E[y_i | \\pmb x_i] = \\phi\\mathrm{Var}[y_i | \\pmb x_i]\\), for extra-poisson dispersion parameter \\(\\phi\\)."
  },
  {
    "objectID": "ch/1_intro.html#resourcesreferences",
    "href": "ch/1_intro.html#resourcesreferences",
    "title": "1  Intro",
    "section": "1.3 Resources/references",
    "text": "1.3 Resources/references\n\nEvans, 1953\nConsul and Jain, 1973\nBulmer, 1974\nJanardan et al, 1979\nGourieroux, 1984\nCT, 1986\nCT, 2013\nConsul and Famoye, 1992\nJoe and Zhu, 2005\nFamoye and Singh, 2006\nGreene, 2008\nWinkelmann, 2008\nHilbe, 2011\nHardon and Hilbe, 2018\nhttps://www.youtube.com/watch?v=uGKnoAw-PFQ\nStatistical Methods Series: Zero-Inflated GLM and GLMM"
  },
  {
    "objectID": "ch/2_poisson.html",
    "href": "ch/2_poisson.html",
    "title": "2  Poisson",
    "section": "",
    "text": "For a regression model \\(Y = \\pmb\\beta\\pmb X + \\epsilon_i\\), the canonical likelihood function when \\(Y\\) is a count variable is the Poisson (\\(Y \\sim Poisson(\\lambda)\\)), with probability mass function\n\\[\nP(Y = y_i |\\pmb x_i) =\n  \\frac{\\exp(-\\lambda_i)\\lambda_i^{y_i}}\n       {\\Gamma(1 + y_i)}\n\\]\nfor \\(E(y_i|\\pmb x_i) = \\lambda_i = \\mu_i = \\exp(\\pmb \\beta \\pmb x_i)\\) and \\(Var(y_i | \\pmb x_i) = \\lambda_i\\). The signature features of the Poisson model are its loglinear conditional mean function \\(\\log E(y_i|\\pmb x_i) = \\log \\mu_i = \\pmb \\beta \\pmb x_i\\) (the log of the conditional mean is linear in the parameters), and equal mean and variance \\(Var(y_i | \\pmb x_i) = \\lambda_i\\) which is also called equidispersion since the dispersion \\(\\frac{\\text{variance}}{\\text{mean}} = 1\\).\nHowever, Poisson models tend to be a poor fit in many ecological contexts due to overdispersion. Overdispersion arises naturally due to heterogeneity (e.g. as fish cluster in preferred habitats; as transient schooling species lead to some very large abundance observations), dependence between observations due to spatial and temporal autocorrelation (e.g. dependence of fish abundance within sites and years), and zero-inflation. It may also be due to artifacts of sampling and not measuring or controlling for key covariates influencing local patterns of fish abundance (e.g. time of day, tides, etc). The most popular distribution for overdispersed counts in ecological studies is the negative binomial (NB), which has been shown to appropriately model overdispersion in a range of ecological contexts (Stoklosa et al, 2022)."
  },
  {
    "objectID": "ch/4_negbin.html#sec-NB1",
    "href": "ch/4_negbin.html#sec-NB1",
    "title": "4  Negative binomial",
    "section": "4.2 Negative Binomial (NB-1)",
    "text": "4.2 Negative Binomial (NB-1)\nThe NB1 (aka linear NB, constant dispersion NB) is derived as a Poisson-gamma mixture model, however the manner of derivation differs from the traditional NB2 model. First derived by Evans (1953), it begins with the Poisson distribution\n\\[\ny_i \\sim \\mathrm{Poisson}(\\lambda_i); \\quad\n  P[Y = y_i | \\lambda_i] =\n  \\frac{e^{-\\lambda_i}\\lambda_i^{y_i}}\n       {y_i!}\n\\]\nFor the NB1, we assume the Poisson parameter itself is distributed gamma as\n\\[\n\\lambda_i \\sim \\mathrm{gamma}(\\mu_i, \\delta)\n\\]\nwhere we assign the mean \\(\\mu_i = \\exp(\\pmb x_i \\pmb\\beta)\\) to the shape parameter, and \\(\\delta\\) is the scale parameter.6 7\n\n\n\n\n\n\nThe above is shown as \\(Gamma(\\delta, \\mu_i)\\) in multiple of Hilbe’s textbooks, where delta is still the scale parameter and mu the shape. Is it Gamma(shape, scale) or Gamma(scale, shape)?\n\n\n\nAs such, the expected value of the Poisson parameter is \\(E[\\lambda_i] = \\mu_i/\\delta\\) and the variance is \\(\\mathrm{Var}[\\lambda_i] = \\mu_i/\\delta^2\\). The resulting Poisson-gamma mixture, integrating out \\(\\lambda\\) can be defined as\n\\[\nf(y_i|\\pmb x_i) = \\int^\\infty_0\n  \\frac{e^{-\\lambda_i}\\lambda_i^{y_i}}\n       {y_i!}\n  \\frac{\\delta^{\\mu_i}\\lambda_i^{\\mu_i - 1}}\n       {\\Gamma(\\mu_i)}\n  \\exp(-\\lambda_i\\delta) \\; d\\lambda\n\\]\nSparing the math8 we get\n\\[\n\\boxed{\n\\begin{align}\n\\textbf{Negative binomial (NB-1)}&: \\quad y_i \\sim \\mathcal{NB}_1\\left(\\mu_i,\\; \\delta \\equiv \\alpha^{-1}\\right) \\\\ \\\\\nP[Y=y_i | \\pmb x_i]\n  &= \\frac{\\Gamma(y_i + \\mu_i)}\n          {\\Gamma(y_i + 1)\\Gamma(\\mu_i)}\n     \\left(\\frac{\\delta}\n                {\\delta + 1}\n     \\right)^{\\mu_i}\n     \\left(\\frac{1}\n                   {\\delta + 1}\n     \\right)^{y_i} \\\\ \\\\\n  &= \\frac{\\Gamma(y_i + \\mu_i)}\n          {\\Gamma(y_i + 1)\\Gamma(\\mu_i)}\n     \\left(\\frac{1}\n                {\\alpha + 1}\n     \\right)^{\\mu_i}\n     \\left(\\frac{\\alpha}\n                {\\alpha + 1}\n     \\right)^{y_i} \\\\ \\\\ \\\\\nE[y_i|\\pmb x_i]\n  &= \\frac{\\exp(\\pmb x_i\\pmb\\beta)}\n          {\\delta}\n  = \\frac{\\mu_i}\n          {\\delta}  \n  =  \\alpha \\mu_i\\\\ \\\\\n\\mathrm{Var}[y_i|\\pmb x_i]\n  &= \\frac{\\mu_i (\\delta + 1)}\n          {\\delta^2}\n  =  \\alpha\\mu_i(\\alpha + 1)\\\\ \\\\\n\\text{for } \\; y_i \\in \\mathbb{Z}^{0+}, \\; \\delta > 0, \\; \\text{and }&\\text{ heterogeneity/overdispersion parameter } \\alpha = 1/\\theta > 0.\\quad\n\\end{align}\n}\n\\tag{4.2}\\]\nAgain we have the nested Poisson model as the boundary case when \\(\\alpha = 0\\).\nThe variance to mean ratio, denoting the ‘extra-Poisson dispersion’ (i.e. overdispersion), is\n\\[\n\\frac{\\text{Variance}}{\\text{Mean}} = \\frac{\\mu_i(\\delta + 1)/\\delta^2}{\\mu_i/\\delta} = \\frac{\\delta + 1}{\\delta} = \\alpha + 1\n\\]\nNotice that unlike the NB2 parameterization, in which the overdispersion was variable, here the overdispersion is constant. This is why the NB1 is sometimes called the constant overdispersion NB.\n\n\n\n\n\n\nWhat’s in a parameterization: NB2 vs. NB1 (CT, 1986)\n\n\n\nThe parameterization of the NB model is determined by the parameterization of the gamma heterogeneity distribution. As such, the NB2 and NB1 parameterizations imply different assumptions about the functional form of heteroscedasticity — a point which is not emphasized in the literature — and hence in general will lead to different estimates of \\(\\pmb\\beta\\). The two alternative specifications of the gamma heterogeneity distribution amount to different parameterizations in the univariate model, but where a regression component is present they lead to different models. This difference is also relevant when we consider the test of the null hypothesis that the distribution of Y is Poisson against the alternative that it is negative binomial.\nNote that for the intercept only model \\(\\mu_i = \\beta\\) (i.e. no \\(x\\) variables in the model), if observations are i.i.d., the specific NB parameterization and resulting difference in model form is of no consequence."
  },
  {
    "objectID": "ch/5_genpois.html#summary",
    "href": "ch/5_genpois.html#summary",
    "title": "5  Generalized Poisson",
    "section": "5.1 Summary",
    "text": "5.1 Summary\n\ncol_names <- c(\n  \"Family\",\n  \"Parameterization\", \n  \"Heterogeneity parameter\",\n  \"Nested models\",\n  \"Extra-poisson dispersion\"\n)\ntab <- data.frame() |>  \n  rbind(c(\n    \"Negative Binomial\", \n    \"NB2\", \n    \"\\\\alpha\", \n    \"Poisson ($\\\\alpha = 0)\", \n    \"\"\n  )) \n  # Add more rows here\n\ncolnames(tab) <- col_names"
  },
  {
    "objectID": "ch/4_negbin.html#sec-NB2",
    "href": "ch/4_negbin.html#sec-NB2",
    "title": "4  Negative binomial",
    "section": "4.1 Negative Binomial (NB-2)",
    "text": "4.1 Negative Binomial (NB-2)\nThe derivation on the negative binomial NB2 is usually illustrated as a Poisson model with gamma heterogeneity, where the gamma noise has a mean of 1.1 An intuitive way to think of this is through the introduction of latent heterogeneity2 (an unobserved effect) to the mean of the Poisson model (Greene, 2008).\nRecall our Poisson model of \\(y_i \\sim \\mathrm{poisson}(\\lambda_i)\\) for \\(\\lambda_i = \\mu_i = \\exp(\\pmb x_i \\pmb\\beta)\\)3 which has the property of equidispersion since \\(E[y_i | \\pmb x_i] = \\mathrm{Var}[y_i | \\pmb x_i] = \\lambda_i\\). We will alter this poisson model to account for extra variance in our data, i.e. overdispersion \\(\\mathrm{Var}[y_i | \\pmb x_i] > E[y_i | \\pmb x_i]\\). We can imagine this extra variance stemming from observation-level deviations from the mean dues to an unobserved effect; we will refer to these deviations as latent heterogeneity. Let \\(\\varepsilon\\) represent this latent heterogeneity, then we can re-express the mean as \\(\\mu_i^* = \\exp(\\pmb x_i \\pmb\\beta + \\varepsilon_i)\\). Here \\(\\varepsilon\\) is its own random variable to which we will assign a probability distribution. Now define \\(h_i = \\exp(\\varepsilon_i)\\) such that\n\\[\ny_i \\sim \\mathrm{poisson}(h_i\\lambda_i)\n\\]\nThis is a common step in the derivation of models for overdispersed counts, where the assumed distribution of \\(h_i\\) leads to different models and parameterizations. For the negative binomial (NB2) model we assume that \\(h_i\\) follows a single-parameter gamma distribution\n\\[\nh_i \\sim \\mathrm{gamma}(k = \\theta, \\; \\theta)\n\\]\nwith mean 1 and variance \\(\\alpha = 1/\\theta\\). The probability density of \\(h_i\\) is then\n\\[\nf(h_i) =\n  \\frac{\\theta^\\theta \\exp(-\\theta h_i)h_i^{\\theta - 1}}\n       {\\Gamma(\\theta)}\n  \\; ;\\;\\; h_i \\geq 0 ,\\; \\theta > 0 \\;.\n\\]\nTo put this in mathematical terms, the negative binomial distribution is a poisson-gamma mixture. Notice that a mean of 1 for \\(h\\) corresponds to a mean of 0 for \\(\\varepsilon\\), i.e. we account for some extra zero-centered deviation around \\(\\pmb x_i \\pmb\\beta\\). To put this another way, for \\(y_i \\sim \\mathrm{poisson}(h_i\\lambda_i)\\), if \\(E[h_i] = 1\\) then we can see that \\(E[y_i] = \\lambda_i\\). I.e. \\(E[h_i] = 1\\) is the multiplicative equivalent of \\(E[\\varepsilon] = 0\\) in the additive case. This kind of mixing based on multiplicative heterogeneity which on average leaves the Poisson mean unchanged allows us to increase the variability in the Poisson mean, and in turn, the variability of the response. Intuitively this will lead to overdispersion and to increased probabilities of the occurrence of low counts and of high counts.\nNow we have our latent heterogeneity within the conditional mean of the Poisson model4 we can write the the conditional distribution \\(f(y_i|x_i, h_i) = \\prod^n_{i=1}g(y_i | h_i\\lambda_i)\\) where \\(g\\) is the probability density function of the \\(\\mathrm{poisson}(h_i \\lambda_i)\\) (Gourieroux, 1984). However, since \\(\\varepsilon\\) is an unobserved variable, and therefore so is \\(h\\), we must integrate \\(h\\) out to obtain the conditional distribution of interest\n\\[\nf(y_i|x_i) = P[Y=y_i | \\pmb x_i] = \\int\n  \\frac{\\exp(-h_i\\lambda_i)(h_i\\lambda_i)^{y_i}}\n       {y_i!}\\times\n  \\frac{\\theta^\\theta \\exp(-\\theta h_i)h_i^{\\theta - 1}}\n       {\\Gamma(\\theta)}dh_i\n\\]\nWe will spare the maths5 and take for granted that we get\n\\[\n\\boxed{\n\\begin{align}\n\\textbf{Negative binomial (NB-2)}&: \\quad y_i \\sim \\mathcal{NB}_2\\left(\\lambda_i \\equiv \\mu_i,\\; \\theta \\equiv \\alpha^{-1}\\right) \\\\ \\\\\n\\text{ A poisson-gamma mixture }& \\text{with} \\; y_i \\sim \\mathrm{poisson}(h_i \\lambda_i) \\text{ and } h_i \\sim \\mathrm{gamma}(\\theta, \\theta) .\n\\\\ \\\\ \\\\\nP[Y=y_i | \\pmb x_i]\n  &= \\frac{\\Gamma(y_i + \\theta)}\n          {\\Gamma(y_i + 1)\\Gamma(\\theta)}\n     \\left(\\frac{\\theta}\n              {\\theta + \\mu_i}\n     \\right)^\\theta\n     \\left(1- \\frac{\\theta}\n                  {\\theta + \\mu_i}\n     \\right)^{y_i}\\\\ \\\\\n  &= \\frac{\\Gamma(y_i + 1/\\alpha)}\n          {\\Gamma(y_i + 1)\\Gamma(1/\\alpha)}\n     \\left(\\frac{1}\n                {\\alpha\\mu_i + 1}\n     \\right)^{1/\\alpha}\n     \\left(1- \\frac{1}\n                   {\\alpha \\mu_i + 1}\n     \\right)^{y_i} \\\\ \\\\ \\\\\nE[y_i|\\pmb x_i] &= \\lambda_i = \\mu_i = \\exp(\\pmb x_i\\pmb\\beta)\\\\ \\\\ \\\\\n\\mathrm{Var}[y_i|\\pmb x_i]\n  &= \\mu_i\\left(\\frac{\\mu_i}{\\theta} + 1 \\right)\\\\\n  &= \\mu_i\\big(\\alpha \\mu_i + 1\\big)\\\\ \\\\ \\\\\n\\text{for } \\; y_i \\in \\mathbb{Z}^{0+}, \\; \\theta > 0, \\; \\text{and }&\\text{heterogeneity/overdispersion parameter } \\alpha = 1/\\theta > 0.\\quad\n\\end{align}\n}\n\\tag{4.1}\\]\nThis is the NB-2 parameterization of the negative binomial model (named by CT, 1986 in reference to the quadratic exponent of \\(\\mu\\) in the conditional variance function) — the standard parameterization for NB regression. Notice that this parameterization, resulting from the inclusion of a latent heterogeneity effect, relaxes the equidispersion restriction of the Poisson model while preserving the same conditional mean.\nThe Poisson model is nested within the NB2 model as the boundary case when \\(\\alpha = 0\\). So is the geometric model when \\(\\alpha = 1\\).\nThe variance to mean ratio describes the ‘extra-Poisson dispersion’ (overdispersion). Here we have \\[\n\\frac{\\text{Variance}}{\\text{Mean}} = \\frac{\\mu_i(\\alpha\\mu_i + 1)}{\\mu_i} = \\alpha\\mu_i + 1\n\\]\nNotice that the overdispersion depends on \\(i\\), i.e. it is variable. This is why the NB2 parameterization is sometimes called the variable overdisperison NB.\n\n\n\n\n\n\nDifferent names for the same thing\n\n\n\nThe negative binomial PMF is found in many different forms. \\(\\lambda\\) or \\(\\mu\\), \\(\\alpha\\) or \\(1/\\theta\\), \\(\\alpha\\) could be called \\(\\phi\\) and \\(\\theta\\) could be \\(\\nu\\). Some authors prefer to leave the gamma scale parameter, \\(\\theta\\), as it is. In this form the heterogeneity parameter (\\(\\theta\\)) is inversely related to the amount of Poisson overdispersion in the data. Most contemporary statisticians, however, prefer a direct relationship. Hence the use of \\(\\alpha = 1/\\theta\\).\n\n\n\n\n\n\n\n\nSummary\n\n\n\nHere we saw the Negative Binomial (NB-2 paramaterization) is a Poisson model with latent heterogeneity distributed as single-parameter gamma. This gamma noise overcomes the equidispersion limitation of the Poisson model, accomodating overdispersed or correlated counts through the addition of an overdispersion parameter in the NB variance, but still retain the same conditional mean. The distribution is parameterized by its mean \\(\\mu_i = \\lambda_i\\) and heterogeneity parameter \\(\\alpha\\) (aka. overdispersion parameter) which is the inverse of the gamma noise parameter \\(\\theta\\). This parameterization is intuitive in the context of regression for overdispersed counts, however many other parameterizations exist.\n\n\n\n\n\n\n\n\nPonder\n\n\n\nHere we distributed our latent heterogeneity term as gamma. What is special about the gamma distribution? What would happen if we used a different distribution? The answers could be in Hilbe (2011)."
  }
]